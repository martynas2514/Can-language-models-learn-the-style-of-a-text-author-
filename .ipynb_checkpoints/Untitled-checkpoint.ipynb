{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74bfd05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from datasets) (21.0)\n",
      "Collecting pyarrow!=4.0.0,>=3.0.0\n",
      "  Downloading pyarrow-6.0.1-cp38-cp38-win_amd64.whl (15.5 MB)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py38-none-any.whl (128 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from datasets) (1.21.3)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-win_amd64.whl (555 kB)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from datasets) (2.26.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp38-cp38-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from datasets) (1.3.4)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp38-cp38-win_amd64.whl (83 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp38-cp38-win_amd64.whl (122 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp38-cp38-win_amd64.whl (45 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: multidict, frozenlist, yarl, async-timeout, aiosignal, pyyaml, fsspec, filelock, dill, aiohttp, xxhash, pyarrow, multiprocess, huggingface-hub, datasets\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 datasets-1.16.1 dill-0.3.4 filelock-3.4.0 frozenlist-1.2.0 fsspec-2021.11.1 huggingface-hub-0.2.1 multidict-5.2.0 multiprocess-0.70.12.2 pyarrow-6.0.1 pyyaml-6.0 xxhash-2.0.2 yarl-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f6b41af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'bertscore', 'bleu', 'bleurt', 'cer', 'chrf', 'code_eval', 'comet', 'competition_math', 'coval', 'cuad', 'f1', 'gleu', 'glue', 'google_bleu', 'indic_glue', 'matthews_correlation', 'meteor', 'pearsonr', 'precision', 'recall', 'rouge', 'sacrebleu', 'sari', 'seqeval', 'spearmanr', 'squad', 'squad_v2', 'super_glue', 'ter', 'wer', 'wiki_split', 'xnli']\n"
     ]
    }
   ],
   "source": [
    "from datasets import list_metrics\n",
    "metrics_list = list_metrics()\n",
    "print(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d424a3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from rouge_score) (1.21.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2021.11.10-cp38-cp38-win_amd64.whl (273 kB)\n",
      "Requirement already satisfied: click in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from nltk->rouge_score) (8.0.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from nltk->rouge_score) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages (from click->nltk->rouge_score) (0.4.4)\n",
      "Installing collected packages: regex, nltk, absl-py, rouge-score\n",
      "Successfully installed absl-py-1.0.0 nltk-3.6.5 regex-2021.11.10 rouge-score-0.0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pycaret 2.3.3 requires pandas-profiling>=2.8.0, which is not installed.\n",
      "pycaret 2.3.3 requires seaborn, which is not installed.\n",
      "pycaret 2.3.3 requires numpy==1.19.5, but you have numpy 1.21.3 which is incompatible.\n",
      "pycaret 2.3.3 requires scikit-learn==0.23.2, but you have scikit-learn 1.0.1 which is incompatible.\n",
      "pycaret 2.3.3 requires scipy<=1.5.4, but you have scipy 1.7.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f69d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dd17a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculates average rouge scores for a list of hypotheses and references\n",
      "Args:\n",
      "    predictions: list of predictions to score. Each predictions\n",
      "        should be a string with tokens separated by spaces.\n",
      "    references: list of reference for each prediction. Each\n",
      "        reference should be a string with tokens separated by spaces.\n",
      "    rouge_types: A list of rouge types to calculate.\n",
      "        Valid names:\n",
      "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
      "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
      "        `\"rougeLSum\"`: rougeLsum splits text using `\"\n",
      "\"`.\n",
      "        See details in https://github.com/huggingface/datasets/issues/617\n",
      "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
      "    use_agregator: Return aggregates if this is set to True\n",
      "Returns:\n",
      "    rouge1: rouge_1 (precision, recall, f1),\n",
      "    rouge2: rouge_2 (precision, recall, f1),\n",
      "    rougeL: rouge_l (precision, recall, f1),\n",
      "    rougeLsum: rouge_lsum (precision, recall, f1)\n",
      "Examples:\n",
      "\n",
      "    >>> rouge = datasets.load_metric('rouge')\n",
      "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
      "    >>> references = [\"hello there\", \"general kenobi\"]\n",
      "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
      "    >>> print(list(results.keys()))\n",
      "    ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
      "    >>> print(results[\"rouge1\"])\n",
      "    AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))\n",
      "    >>> print(results[\"rouge1\"].mid.fmeasure)\n",
      "    1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metric.inputs_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2aec2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = metric.compute(predictions=[\"hello there\", \"general kenobi\"], references=[\"hello\", \"general\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0401e24d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.5, recall=1.0, fmeasure=0.6666666666666666), mid=Score(precision=0.5, recall=1.0, fmeasure=0.6666666666666666), high=Score(precision=0.5, recall=1.0, fmeasure=0.6666666666666666)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.0, recall=0.0, fmeasure=0.0), mid=Score(precision=0.0, recall=0.0, fmeasure=0.0), high=Score(precision=0.0, recall=0.0, fmeasure=0.0)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.5, recall=1.0, fmeasure=0.6666666666666666), mid=Score(precision=0.5, recall=1.0, fmeasure=0.6666666666666666), high=Score(precision=0.5, recall=1.0, fmeasure=0.6666666666666666)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.5, recall=1.0, fmeasure=0.6666666666666666), mid=Score(precision=0.5, recall=1.0, fmeasure=0.6666666666666666), high=Score(precision=0.5, recall=1.0, fmeasure=0.6666666666666666))}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d026ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Trumptweetsclassifier.predict import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32133669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, array([0.93418058, 0.06581942])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e30f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you. Thank you. Thank you to Vice Presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There's a lot of people. That's great. Thank y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you. Thank you. Thank you. All I can say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to thank you very much. North Carolina,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you all. Thank you very much. Thank you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Thank you. Thank you. Thank you to Vice Presid...\n",
       "1  There's a lot of people. That's great. Thank y...\n",
       "2  Thank you. Thank you. Thank you. All I can say...\n",
       "3  I want to thank you very much. North Carolina,...\n",
       "4  Thank you all. Thank you very much. Thank you ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "cols = ['text']\n",
    "df = pd.DataFrame(columns=cols, index=range(35))\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(\"trump_speeches\"):\n",
    "    path = \"trump_speeches/\"+filename\n",
    "    with open(path, encoding = 'cp850') as f:\n",
    "        fileText = f.read()\n",
    "    \n",
    "    #print(fileLoc, fileMonth, fileYear, fileText)\n",
    "    df.append([fileText])\n",
    "    df.loc[i].text = fileText\n",
    "    i+=1\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71240f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, array([0.41493562, 0.58506438])] 95916\n",
      "[1.0, array([0.49683271, 0.50316729])] 89833\n",
      "[1.0, array([0.08574006, 0.91425994])] 51876\n",
      "[1.0, array([0.12585369, 0.87414631])] 37189\n",
      "[1.0, array([0.08210995, 0.91789005])] 44984\n",
      "[1.0, array([0.16929863, 0.83070137])] 63212\n",
      "[1.0, array([0.15016865, 0.84983135])] 57143\n",
      "[1.0, array([0.14188383, 0.85811617])] 64560\n",
      "[1.0, array([0.29742706, 0.70257294])] 87099\n",
      "[1.0, array([0.10329581, 0.89670419])] 50534\n",
      "[1.0, array([0.15763909, 0.84236091])] 54995\n",
      "[1.0, array([0.18372937, 0.81627063])] 58205\n",
      "[1.0, array([0.05673392, 0.94326608])] 49162\n",
      "[1.0, array([0.13805528, 0.86194472])] 54726\n",
      "[1.0, array([0.36847554, 0.63152446])] 74708\n",
      "[1.0, array([0.20659085, 0.79340915])] 67566\n",
      "[1.0, array([0.09435314, 0.90564686])] 49765\n",
      "[1.0, array([0.1782982, 0.8217018])] 52285\n",
      "[1.0, array([0.19805977, 0.80194023])] 76858\n",
      "[1.0, array([0.20551257, 0.79448743])] 63515\n",
      "[1.0, array([0.28179747, 0.71820253])] 78192\n",
      "[1.0, array([0.10641334, 0.89358666])] 55428\n",
      "[1.0, array([0.17027664, 0.82972336])] 49444\n",
      "[1.0, array([0.0627753, 0.9372247])] 36876\n",
      "[1.0, array([0.19304405, 0.80695595])] 63349\n",
      "[1.0, array([0.14976591, 0.85023409])] 58336\n",
      "[1.0, array([0.11496665, 0.88503335])] 52718\n",
      "[1.0, array([0.21436003, 0.78563997])] 65090\n",
      "[1.0, array([0.00439269, 0.99560731])] 14616\n",
      "[1.0, array([0.25137334, 0.74862666])] 58815\n",
      "[1.0, array([0.20383017, 0.79616983])] 61189\n",
      "[1.0, array([0.13812015, 0.86187985])] 51248\n",
      "[1.0, array([0.07530674, 0.92469326])] 39007\n",
      "[1.0, array([0.16063967, 0.83936033])] 60863\n",
      "[1.0, array([0.08437841, 0.91562159])] 34486\n"
     ]
    }
   ],
   "source": [
    "for i in df.text:\n",
    "    print(predict(i), len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "225663b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_split = df.text[0].split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69e92558",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "too_short_save = \"\"\n",
    "mem_words = 0\n",
    "for i in dot_split:\n",
    "    words = i.split(\" \")\n",
    "    if (len(words) + mem_words) < 100: \n",
    "        too_short_save = \". \".join([too_short_save, i])\n",
    "        mem_words = mem_words + len(words)\n",
    "    else:\n",
    "        too_short_save = \". \".join([too_short_save, i])\n",
    "        sentences.append(too_short_save)\n",
    "        mem_words = 0\n",
    "        too_short_save = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5dc8a429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.0 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.0 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator SGDClassifier from version 0.23.0 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\marty\\anaconda3\\envs\\text_mining\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.0 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cols = ['text', \"pred\", \"prob\", \"len\"]\n",
    "df = pd.DataFrame(columns=cols)\n",
    "itt=0\n",
    "for i in sentences:\n",
    "    pred = predict(i)\n",
    "    df.loc[itt] = [i, pred[0], pred[1][1], len(i.split(\" \"))]\n",
    "    itt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1e1c399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>. Thank you.  Thank you.  Thank you to Vice Pr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.797037</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.  I remember when I first started this beauti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933914</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.  Nobody's ever had this kind of support.  Bu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.627497</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.  But she's not fixing the potholes.  But Mic...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222320</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.  And that was long before I ever decided to ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.816254</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>.  I'm telling you, they're as bad as China, j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841781</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>.  They don't want to talk about it.  They tal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105274</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>.  A lot of these countries, France, they like...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138745</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>.  They'd like me so much, but then I'm not do...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366887</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>.  I'll say, \"That state let me down. \" I don'...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264353</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  pred      prob  len\n",
       "0    . Thank you.  Thank you.  Thank you to Vice Pr...   1.0  0.797037  109\n",
       "1    .  I remember when I first started this beauti...   1.0  0.933914  104\n",
       "2    .  Nobody's ever had this kind of support.  Bu...   1.0  0.627497  101\n",
       "3    .  But she's not fixing the potholes.  But Mic...   0.0  0.222320  104\n",
       "4    .  And that was long before I ever decided to ...   1.0  0.816254  161\n",
       "..                                                 ...   ...       ...  ...\n",
       "173  .  I'm telling you, they're as bad as China, j...   1.0  0.841781  112\n",
       "174  .  They don't want to talk about it.  They tal...   0.0  0.105274  104\n",
       "175  .  A lot of these countries, France, they like...   0.0  0.138745  108\n",
       "176  .  They'd like me so much, but then I'm not do...   0.0  0.366887  113\n",
       "177  .  I'll say, \"That state let me down. \" I don'...   0.0  0.264353  104\n",
       "\n",
       "[178 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e9dc370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4438202247191011"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pred.sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1079e20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. \" I said, \"That\\'s okay, don\\'t worry about it. \" Maybe he\\'s looking up? I don\\'t know.  I don\\'t know.  Maybe, maybe.  But let\\'s assume he\\'s looking down.  But I gave him A+, not A, not B+, not B.  I gave him the A+, and she called me.  She said, \"Oh, no. \" I won\\'t go into the conversation, because it\\'s not fair do that.  But all I want to say is, let\\'s put it this way, it was the most profuse thank you that you could ever get on a scale of zero to 10, it was a 10'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.prob == min(df.prob)].text[84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b718e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".  We believe in the dignity of work and the sanctity of life.  We believe that faith and family, not government bureaucracy are the true American way.  We believe that children should be taught to love our country, honor our history, and to always respect our great American flag.  And we live by the words of our national motto and it's always going to be up there.  They want to take everything down.  They don't want Thomas Jefferson anymore.  They don't want anything.  That's a terrible thing and we fight for it, now\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.prob == max(df.prob)].text[166]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97382bdf",
   "metadata": {},
   "source": [
    "## word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "945a9bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "trump_corpus = \"\"\n",
    "\n",
    "\n",
    "for filename in os.listdir(\"trump_speeches\"):\n",
    "    path = \"trump_speeches/\"+filename\n",
    "    with open(path, encoding = 'cp850') as f:\n",
    "        fileText = f.read()\n",
    "        trump_corpus = trump_corpus + fileText + \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8906801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370480"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trump_corpus.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9b004f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "else_corpus = \"\"\n",
    "\n",
    "\n",
    "for filename in os.listdir(\"Biden_speeches\"):\n",
    "    path = \"Biden_speeches/\"+filename\n",
    "    with open(path, encoding = 'cp850') as f:\n",
    "        fileText = f.read()\n",
    "        else_corpus = else_corpus + fileText + \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8339433c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109709"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(else_corpus.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218a9a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
