{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f198641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "545a0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_splits/trumpClassifierText.txt\", encoding = \"utf-8\") as f:\n",
    "    trump = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0513e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_splits/othersClassifierText.txt\", encoding = \"utf-8\") as f:\n",
    "    others = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d963260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTolenWords(text, nwords):\n",
    "    words = text.split(\" \")\n",
    "    count = int(len(words)/nwords)\n",
    "    sentences = [\" \".join(words[(i*nwords):((i+1)*nwords)]) for i in range(count)]\n",
    "    return(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2458f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets try to make <M> bleu \n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "def unnameTextWithM(text):\n",
    "    nlp = en_core_web_sm.load()\n",
    "    doc = nlp(text)\n",
    "    text = text\n",
    "    for ent in reversed(doc.ents):\n",
    "        text = text[:ent.start_char] + \"<M>\" + text[ent.end_char:] \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58c0086",
   "metadata": {},
   "outputs": [],
   "source": [
    "unnameTrump = unnameTextWithM(trump)\n",
    "unnameOthers = unnameTextWithM(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a506faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trumpSentenceList = splitTolenWords(unnameTrump, 100)\n",
    "OtherSentenceList = splitTolenWords(unnameOthers, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2557e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "trump_labels = np.repeat(1,len(trumpSentenceList))\n",
    "others_labels = np.repeat(0,len(OtherSentenceList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a307bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.concatenate([trumpSentenceList, OtherSentenceList], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2d913a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate([trump_labels, others_labels], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70751de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "62fc87f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_x,test_x,tv_y,test_y = train_test_split(sentences, labels, test_size = 0.2)\n",
    "train_x,valid_x,train_y,valid_y = train_test_split(tv_x, tv_y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6fc9aa6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        71\n",
      "           1       0.94      0.94      0.94        84\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.94      0.94      0.94       155\n",
      "weighted avg       0.94      0.94      0.94       155\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86        71\n",
      "           1       0.86      0.90      0.88        84\n",
      "\n",
      "    accuracy                           0.87       155\n",
      "   macro avg       0.87      0.87      0.87       155\n",
      "weighted avg       0.87      0.87      0.87       155\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        71\n",
      "           1       0.94      0.88      0.91        84\n",
      "\n",
      "    accuracy                           0.90       155\n",
      "   macro avg       0.90      0.91      0.90       155\n",
      "weighted avg       0.91      0.90      0.90       155\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92        71\n",
      "           1       0.94      0.92      0.93        84\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.92      0.92      0.92       155\n",
      "weighted avg       0.92      0.92      0.92       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('clf', MultinomialNB()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(train_x, train_y) \n",
    "print(classification_report(valid_y, text_clf.predict(valid_x)))\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('clf', GradientBoostingClassifier()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(train_x, train_y) \n",
    "print(classification_report(valid_y, text_clf.predict(valid_x)))\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('clf', svm.SVC()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(train_x, train_y) \n",
    "print(classification_report(valid_y, text_clf.predict(valid_x)))\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('clf', LogisticRegression()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(train_x, train_y) \n",
    "print(classification_report(valid_y, text_clf.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ca66bf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9417427733556766\n",
      "Best Params:  {'clf__alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('clf', MultinomialNB()),\n",
    "                     ])\n",
    "\n",
    "parameters = {'clf__alpha':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]}\n",
    "clf = GridSearchCV(text_clf, parameters)\n",
    "clf.fit(tv_x, tv_y)\n",
    "\n",
    "print(\"Best Score: \", clf.best_score_)\n",
    "print(\"Best Params: \", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "455405d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92        97\n",
      "           1       0.91      0.94      0.92        96\n",
      "\n",
      "    accuracy                           0.92       193\n",
      "   macro avg       0.92      0.92      0.92       193\n",
      "weighted avg       0.92      0.92      0.92       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('clf', MultinomialNB(alpha = 0.5)),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(tv_x, tv_y)\n",
    "print(classification_report(test_y, text_clf.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e8fb300d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(stop_words='english')),\n",
       "                ('clf', MultinomialNB(alpha=0.5))])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final classifier will be trained on whole dataset \n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('clf', MultinomialNB(alpha = 0.5)),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(sentences, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "5dd7eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\" residents up for reelection usually ask if the country is better off than it was four years ago.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "c9046ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97689832, 0.02310168]])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict_proba(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "560ea002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_pi = open('classifiers/Textclassifier.obj', 'wb') \n",
    "pickle.dump(text_clf, file_pi)\n",
    "file_pi.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6fab69",
   "metadata": {},
   "source": [
    "# classifier based on POS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e1a18a",
   "metadata": {},
   "source": [
    "## data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d8abf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ab26ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "def posTag(text):\n",
    "    doc = nlp(str(text))\n",
    "    pos = \"\"\n",
    "    dep = \"\"\n",
    "    for token in doc:\n",
    "        pos = pos + token.pos_ + \" \"\n",
    "        dep = dep + token.dep_ + \" \"\n",
    "    return pos, dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2250da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "posSentences, detSentences = map(list,zip(*[posTag(sentence) for sentence in sentences]))\n",
    "t1 = Tokenizer()\n",
    "t1.fit_on_texts(posSentences)\n",
    "t2 = Tokenizer()\n",
    "t2.fit_on_texts(detSentences)\n",
    "res1 = t1.texts_to_sequences(posSentences)\n",
    "res2 = t2.texts_to_sequences(detSentences)\n",
    "vocabsize1 = len(t1.word_index)+1\n",
    "vocabsize2 = len(t2.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3766b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = pad_sequences(\n",
    "    res1, maxlen=200, dtype='int32', padding='post',\n",
    "    truncating='post', value=0\n",
    ")\n",
    "\n",
    "x2 = pad_sequences(\n",
    "    res2, maxlen=200, dtype='int32', padding='post',\n",
    "    truncating='post', value=0\n",
    ")\n",
    "\n",
    "x = np.concatenate((x1[:,:,tf.newaxis],x2[:,:,tf.newaxis]), axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06812593",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8636/2923278641.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "y = to_categorical(labels)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "861634c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_x,test_x,tv_y,test_y = train_test_split(x, y, test_size = 0.2)\n",
    "train_x,valid_x,train_y,valid_y = train_test_split(tv_x, tv_y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "497d131d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabsize1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30777ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabsize2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32743f8e",
   "metadata": {},
   "source": [
    "## model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba45bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible1 = layers.Input(shape= (200,))\n",
    "visible2 = layers.Input(shape= (200,))\n",
    "x1 = layers.Embedding(input_dim=vocabsize1, output_dim=20)(visible1)\n",
    "x2 = layers.Embedding(input_dim=vocabsize2, output_dim=20)(visible2)\n",
    "x = layers.Concatenate(axis = 2)([x1, x2])\n",
    "x = layers.Bidirectional(layers.LSTM(40, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(40))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(40,activation='relu')(x)\n",
    "output = layers.Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=[visible1, visible2], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daf91029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 200, 20)      380         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 20)      880         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 200, 40)      0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 200, 80)      25920       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 80)           38720       bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 80)           0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 40)           3240        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            82          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 69,222\n",
      "Trainable params: 69,222\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fd3500cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "a3157c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "20/20 [==============================] - 2s 100ms/step - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6892 - val_accuracy: 0.4839\n",
      "Epoch 2/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.6514 - accuracy: 0.6418 - val_loss: 0.5611 - val_accuracy: 0.7097\n",
      "Epoch 3/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.5795 - accuracy: 0.7164 - val_loss: 0.5372 - val_accuracy: 0.7355\n",
      "Epoch 4/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.5494 - accuracy: 0.7585 - val_loss: 0.5770 - val_accuracy: 0.7097\n",
      "Epoch 5/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.5319 - accuracy: 0.7553 - val_loss: 0.5289 - val_accuracy: 0.7290\n",
      "Epoch 6/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.5131 - accuracy: 0.7618 - val_loss: 0.5161 - val_accuracy: 0.7548\n",
      "Epoch 7/200\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.5207 - accuracy: 0.7747 - val_loss: 0.5345 - val_accuracy: 0.7548\n",
      "Epoch 8/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4731 - accuracy: 0.7909 - val_loss: 0.4788 - val_accuracy: 0.7871\n",
      "Epoch 9/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4059 - accuracy: 0.8363 - val_loss: 0.4608 - val_accuracy: 0.7935\n",
      "Epoch 10/200\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4091 - accuracy: 0.8266 - val_loss: 0.4474 - val_accuracy: 0.8194\n",
      "Epoch 11/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4029 - accuracy: 0.8444 - val_loss: 0.4434 - val_accuracy: 0.8000\n",
      "Epoch 12/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3673 - accuracy: 0.8493 - val_loss: 0.4750 - val_accuracy: 0.8000\n",
      "Epoch 13/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3872 - accuracy: 0.8444 - val_loss: 0.5465 - val_accuracy: 0.7484\n",
      "Epoch 14/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3752 - accuracy: 0.8379 - val_loss: 0.4384 - val_accuracy: 0.8065\n",
      "Epoch 15/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3424 - accuracy: 0.8768 - val_loss: 0.4206 - val_accuracy: 0.7935\n",
      "Epoch 16/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3317 - accuracy: 0.8768 - val_loss: 0.4308 - val_accuracy: 0.8129\n",
      "Epoch 17/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3341 - accuracy: 0.8768 - val_loss: 0.5042 - val_accuracy: 0.8000\n",
      "Epoch 18/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3309 - accuracy: 0.8703 - val_loss: 0.4504 - val_accuracy: 0.8065\n",
      "Epoch 19/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3397 - accuracy: 0.8703 - val_loss: 0.4573 - val_accuracy: 0.7806\n",
      "Epoch 20/200\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3463 - accuracy: 0.8574 - val_loss: 0.4646 - val_accuracy: 0.8000\n",
      "Epoch 21/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3441 - accuracy: 0.8752 - val_loss: 0.4376 - val_accuracy: 0.8129\n",
      "Epoch 22/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3371 - accuracy: 0.8606 - val_loss: 0.4228 - val_accuracy: 0.7935\n",
      "Epoch 23/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3162 - accuracy: 0.8833 - val_loss: 0.4216 - val_accuracy: 0.8129\n",
      "Epoch 24/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3037 - accuracy: 0.8784 - val_loss: 0.4722 - val_accuracy: 0.8129\n",
      "Epoch 25/200\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3176 - accuracy: 0.8768 - val_loss: 0.4924 - val_accuracy: 0.8194\n",
      "Epoch 26/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3268 - accuracy: 0.8639 - val_loss: 0.4359 - val_accuracy: 0.8194\n",
      "Epoch 27/200\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.3062 - accuracy: 0.8849 - val_loss: 0.4221 - val_accuracy: 0.8194\n",
      "Epoch 28/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3056 - accuracy: 0.8671 - val_loss: 0.5226 - val_accuracy: 0.7871\n",
      "Epoch 29/200\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.3634 - accuracy: 0.8558 - val_loss: 0.4392 - val_accuracy: 0.8258\n",
      "Epoch 30/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3133 - accuracy: 0.8784 - val_loss: 0.4083 - val_accuracy: 0.8323\n",
      "Epoch 31/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3360 - accuracy: 0.8671 - val_loss: 0.4259 - val_accuracy: 0.8452\n",
      "Epoch 32/200\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2828 - accuracy: 0.8898 - val_loss: 0.4732 - val_accuracy: 0.8129\n",
      "Epoch 33/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4298 - accuracy: 0.8071 - val_loss: 0.5466 - val_accuracy: 0.7548\n",
      "Epoch 34/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4293 - accuracy: 0.8298 - val_loss: 0.5346 - val_accuracy: 0.7484\n",
      "Epoch 35/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4000 - accuracy: 0.8412 - val_loss: 0.4373 - val_accuracy: 0.8129\n",
      "Epoch 36/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3524 - accuracy: 0.8558 - val_loss: 0.4303 - val_accuracy: 0.8194\n",
      "Epoch 37/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3035 - accuracy: 0.8784 - val_loss: 0.5205 - val_accuracy: 0.7935\n",
      "Epoch 38/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3450 - accuracy: 0.8574 - val_loss: 0.4571 - val_accuracy: 0.8194\n",
      "Epoch 39/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3246 - accuracy: 0.8817 - val_loss: 0.5102 - val_accuracy: 0.8065\n",
      "Epoch 40/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3382 - accuracy: 0.8590 - val_loss: 0.5381 - val_accuracy: 0.8194\n",
      "Epoch 41/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3169 - accuracy: 0.8849 - val_loss: 0.4738 - val_accuracy: 0.8194\n",
      "Epoch 42/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2912 - accuracy: 0.8882 - val_loss: 0.4534 - val_accuracy: 0.8258\n",
      "Epoch 43/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2613 - accuracy: 0.8979 - val_loss: 0.4838 - val_accuracy: 0.8194\n",
      "Epoch 44/200\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.2849 - accuracy: 0.8801 - val_loss: 0.4555 - val_accuracy: 0.8194\n",
      "Epoch 45/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2972 - accuracy: 0.8784 - val_loss: 0.4597 - val_accuracy: 0.8129\n",
      "Epoch 46/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3181 - accuracy: 0.8671 - val_loss: 0.6027 - val_accuracy: 0.7871\n",
      "Epoch 47/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2856 - accuracy: 0.8801 - val_loss: 0.4764 - val_accuracy: 0.8065\n",
      "Epoch 48/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2486 - accuracy: 0.9028 - val_loss: 0.5442 - val_accuracy: 0.8194\n",
      "Epoch 49/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2569 - accuracy: 0.9044 - val_loss: 0.4965 - val_accuracy: 0.8387\n",
      "Epoch 50/200\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.2404 - accuracy: 0.9109 - val_loss: 0.5106 - val_accuracy: 0.8129\n",
      "Epoch 51/200\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.2537 - accuracy: 0.8963 - val_loss: 0.4677 - val_accuracy: 0.7742\n",
      "Epoch 52/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3464 - accuracy: 0.8541 - val_loss: 0.6134 - val_accuracy: 0.7806\n",
      "Epoch 53/200\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3015 - accuracy: 0.8736 - val_loss: 0.5867 - val_accuracy: 0.8129\n",
      "Epoch 54/200\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.3112 - accuracy: 0.8703 - val_loss: 0.6057 - val_accuracy: 0.8194\n",
      "Epoch 55/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2540 - accuracy: 0.8914 - val_loss: 0.5818 - val_accuracy: 0.8323\n",
      "Epoch 56/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2409 - accuracy: 0.9028 - val_loss: 0.6254 - val_accuracy: 0.8387\n",
      "Epoch 57/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2239 - accuracy: 0.9141 - val_loss: 0.7125 - val_accuracy: 0.8129\n",
      "Epoch 58/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2315 - accuracy: 0.9125 - val_loss: 0.6084 - val_accuracy: 0.8000\n",
      "Epoch 59/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2267 - accuracy: 0.9044 - val_loss: 0.5830 - val_accuracy: 0.7806\n",
      "Epoch 60/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3297 - accuracy: 0.8606 - val_loss: 1.0923 - val_accuracy: 0.7355\n",
      "Epoch 61/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.5116 - accuracy: 0.8023 - val_loss: 0.6229 - val_accuracy: 0.6129\n",
      "Epoch 62/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.5620 - accuracy: 0.7196 - val_loss: 0.5651 - val_accuracy: 0.7613\n",
      "Epoch 63/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4370 - accuracy: 0.8266 - val_loss: 0.4969 - val_accuracy: 0.7548\n",
      "Epoch 64/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3712 - accuracy: 0.8379 - val_loss: 0.4669 - val_accuracy: 0.8129\n",
      "Epoch 65/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3970 - accuracy: 0.8347 - val_loss: 0.7574 - val_accuracy: 0.7742\n",
      "Epoch 66/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4302 - accuracy: 0.8412 - val_loss: 0.4819 - val_accuracy: 0.7806\n",
      "Epoch 67/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3705 - accuracy: 0.8412 - val_loss: 0.5110 - val_accuracy: 0.7935\n",
      "Epoch 68/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3412 - accuracy: 0.8574 - val_loss: 0.5514 - val_accuracy: 0.7871\n",
      "Epoch 69/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3209 - accuracy: 0.8541 - val_loss: 0.5358 - val_accuracy: 0.7935\n",
      "Epoch 70/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3203 - accuracy: 0.8639 - val_loss: 0.5700 - val_accuracy: 0.7871\n",
      "Epoch 71/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3055 - accuracy: 0.8687 - val_loss: 0.5864 - val_accuracy: 0.7935\n",
      "Epoch 72/200\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2838 - accuracy: 0.8736 - val_loss: 0.5942 - val_accuracy: 0.8129\n",
      "Epoch 73/200\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.2668 - accuracy: 0.9076 - val_loss: 0.5889 - val_accuracy: 0.8323\n",
      "Epoch 74/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3172 - accuracy: 0.8671 - val_loss: 0.6532 - val_accuracy: 0.7161\n",
      "Epoch 75/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3408 - accuracy: 0.8493 - val_loss: 0.5628 - val_accuracy: 0.8129\n",
      "Epoch 76/200\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.2582 - accuracy: 0.9028 - val_loss: 0.6976 - val_accuracy: 0.7806\n",
      "Epoch 77/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2981 - accuracy: 0.8736 - val_loss: 0.5808 - val_accuracy: 0.8000\n",
      "Epoch 78/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2375 - accuracy: 0.9141 - val_loss: 0.6044 - val_accuracy: 0.8000\n",
      "Epoch 79/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2344 - accuracy: 0.9206 - val_loss: 0.6087 - val_accuracy: 0.7742\n",
      "Epoch 80/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2146 - accuracy: 0.9238 - val_loss: 0.7818 - val_accuracy: 0.8258\n",
      "Epoch 81/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2544 - accuracy: 0.9044 - val_loss: 0.5852 - val_accuracy: 0.8129\n",
      "Epoch 82/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2174 - accuracy: 0.9109 - val_loss: 0.6753 - val_accuracy: 0.8129\n",
      "Epoch 83/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2206 - accuracy: 0.9190 - val_loss: 0.8225 - val_accuracy: 0.7806\n",
      "Epoch 84/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2187 - accuracy: 0.9206 - val_loss: 0.6032 - val_accuracy: 0.7935\n",
      "Epoch 85/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2561 - accuracy: 0.9028 - val_loss: 0.6667 - val_accuracy: 0.8065\n",
      "Epoch 86/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2380 - accuracy: 0.8930 - val_loss: 0.5944 - val_accuracy: 0.8129\n",
      "Epoch 87/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2101 - accuracy: 0.9125 - val_loss: 0.6749 - val_accuracy: 0.8258\n",
      "Epoch 88/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2354 - accuracy: 0.9028 - val_loss: 0.7052 - val_accuracy: 0.7806\n",
      "Epoch 89/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2387 - accuracy: 0.9060 - val_loss: 0.6245 - val_accuracy: 0.8194\n",
      "Epoch 90/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1888 - accuracy: 0.9319 - val_loss: 0.7664 - val_accuracy: 0.8129\n",
      "Epoch 91/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2021 - accuracy: 0.9206 - val_loss: 0.7215 - val_accuracy: 0.8000\n",
      "Epoch 92/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2183 - accuracy: 0.9173 - val_loss: 0.7283 - val_accuracy: 0.8065\n",
      "Epoch 93/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1838 - accuracy: 0.9335 - val_loss: 0.6876 - val_accuracy: 0.8129\n",
      "Epoch 94/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2038 - accuracy: 0.9303 - val_loss: 0.7172 - val_accuracy: 0.7935\n",
      "Epoch 95/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2558 - accuracy: 0.9076 - val_loss: 0.6636 - val_accuracy: 0.8387\n",
      "Epoch 96/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1937 - accuracy: 0.9303 - val_loss: 0.7576 - val_accuracy: 0.8258\n",
      "Epoch 97/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1785 - accuracy: 0.9368 - val_loss: 0.8020 - val_accuracy: 0.8000\n",
      "Epoch 98/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1906 - accuracy: 0.9417 - val_loss: 0.7663 - val_accuracy: 0.8065\n",
      "Epoch 99/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2076 - accuracy: 0.9092 - val_loss: 0.7271 - val_accuracy: 0.8065\n",
      "Epoch 100/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2362 - accuracy: 0.9060 - val_loss: 0.7341 - val_accuracy: 0.7871\n",
      "Epoch 101/200\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.1887 - accuracy: 0.9238 - val_loss: 0.7230 - val_accuracy: 0.8129\n",
      "Epoch 102/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1593 - accuracy: 0.9335 - val_loss: 0.7997 - val_accuracy: 0.8000\n",
      "Epoch 103/200\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.1433 - accuracy: 0.9530 - val_loss: 0.8949 - val_accuracy: 0.8323\n",
      "Epoch 104/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1808 - accuracy: 0.9271 - val_loss: 0.7983 - val_accuracy: 0.8065\n",
      "Epoch 105/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1575 - accuracy: 0.9400 - val_loss: 0.8171 - val_accuracy: 0.8065\n",
      "Epoch 106/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2121 - accuracy: 0.9335 - val_loss: 0.6469 - val_accuracy: 0.8194\n",
      "Epoch 107/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2938 - accuracy: 0.8768 - val_loss: 0.6683 - val_accuracy: 0.8452\n",
      "Epoch 108/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2270 - accuracy: 0.9157 - val_loss: 0.6189 - val_accuracy: 0.8000\n",
      "Epoch 109/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1788 - accuracy: 0.9368 - val_loss: 0.7799 - val_accuracy: 0.8194\n",
      "Epoch 110/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1847 - accuracy: 0.9335 - val_loss: 0.7877 - val_accuracy: 0.7935\n",
      "Epoch 111/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1608 - accuracy: 0.9400 - val_loss: 0.8485 - val_accuracy: 0.8065\n",
      "Epoch 112/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1707 - accuracy: 0.9319 - val_loss: 0.7233 - val_accuracy: 0.7677\n",
      "Epoch 113/200\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.2066 - accuracy: 0.9141 - val_loss: 0.7054 - val_accuracy: 0.7677\n",
      "Epoch 114/200\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.2323 - accuracy: 0.9028 - val_loss: 0.9009 - val_accuracy: 0.7935\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1716 - accuracy: 0.9335 - val_loss: 0.8113 - val_accuracy: 0.8000\n",
      "Epoch 116/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1766 - accuracy: 0.9352 - val_loss: 0.9327 - val_accuracy: 0.8000\n",
      "Epoch 117/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1513 - accuracy: 0.9465 - val_loss: 0.8846 - val_accuracy: 0.7548\n",
      "Epoch 118/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1602 - accuracy: 0.9449 - val_loss: 1.0175 - val_accuracy: 0.8323\n",
      "Epoch 119/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1867 - accuracy: 0.9303 - val_loss: 0.7206 - val_accuracy: 0.7935\n",
      "Epoch 120/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1505 - accuracy: 0.9498 - val_loss: 0.8870 - val_accuracy: 0.8129\n",
      "Epoch 121/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1277 - accuracy: 0.9627 - val_loss: 1.5666 - val_accuracy: 0.7290\n",
      "Epoch 122/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.5419 - accuracy: 0.8185 - val_loss: 0.4569 - val_accuracy: 0.7871\n",
      "Epoch 123/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2458 - accuracy: 0.9028 - val_loss: 0.5825 - val_accuracy: 0.8258\n",
      "Epoch 124/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2161 - accuracy: 0.9060 - val_loss: 0.5824 - val_accuracy: 0.8065\n",
      "Epoch 125/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1721 - accuracy: 0.9384 - val_loss: 0.6370 - val_accuracy: 0.7935\n",
      "Epoch 126/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1754 - accuracy: 0.9433 - val_loss: 0.7191 - val_accuracy: 0.8065\n",
      "Epoch 127/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1698 - accuracy: 0.9319 - val_loss: 0.7000 - val_accuracy: 0.8065\n",
      "Epoch 128/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1876 - accuracy: 0.9206 - val_loss: 0.7351 - val_accuracy: 0.7935\n",
      "Epoch 129/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1524 - accuracy: 0.9546 - val_loss: 0.6933 - val_accuracy: 0.8258\n",
      "Epoch 130/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1375 - accuracy: 0.9514 - val_loss: 0.7707 - val_accuracy: 0.7871\n",
      "Epoch 131/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1387 - accuracy: 0.9514 - val_loss: 0.8435 - val_accuracy: 0.8065\n",
      "Epoch 132/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1336 - accuracy: 0.9562 - val_loss: 0.8995 - val_accuracy: 0.8065\n",
      "Epoch 133/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1250 - accuracy: 0.9676 - val_loss: 0.8884 - val_accuracy: 0.7871\n",
      "Epoch 134/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1397 - accuracy: 0.9449 - val_loss: 0.9488 - val_accuracy: 0.8129\n",
      "Epoch 135/200\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.1652 - accuracy: 0.9465 - val_loss: 0.8103 - val_accuracy: 0.7742\n",
      "Epoch 136/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2021 - accuracy: 0.9173 - val_loss: 0.7506 - val_accuracy: 0.7935\n",
      "Epoch 137/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1657 - accuracy: 0.9368 - val_loss: 0.7812 - val_accuracy: 0.8194\n",
      "Epoch 138/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1635 - accuracy: 0.9481 - val_loss: 0.9103 - val_accuracy: 0.8194\n",
      "Epoch 139/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1509 - accuracy: 0.9449 - val_loss: 0.8806 - val_accuracy: 0.8065\n",
      "Epoch 140/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1257 - accuracy: 0.9611 - val_loss: 0.9286 - val_accuracy: 0.7871\n",
      "Epoch 141/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1225 - accuracy: 0.9611 - val_loss: 0.8191 - val_accuracy: 0.7806\n",
      "Epoch 142/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2901 - accuracy: 0.8882 - val_loss: 0.7593 - val_accuracy: 0.6968\n",
      "Epoch 143/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2705 - accuracy: 0.8914 - val_loss: 0.6893 - val_accuracy: 0.7806\n",
      "Epoch 144/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2121 - accuracy: 0.9287 - val_loss: 0.6353 - val_accuracy: 0.7806\n",
      "Epoch 145/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1504 - accuracy: 0.9530 - val_loss: 0.7334 - val_accuracy: 0.7935\n",
      "Epoch 146/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1315 - accuracy: 0.9579 - val_loss: 0.8736 - val_accuracy: 0.7935\n",
      "Epoch 147/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1082 - accuracy: 0.9627 - val_loss: 0.8635 - val_accuracy: 0.7871\n",
      "Epoch 148/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1038 - accuracy: 0.9676 - val_loss: 0.9482 - val_accuracy: 0.7806\n",
      "Epoch 149/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1045 - accuracy: 0.9676 - val_loss: 0.9331 - val_accuracy: 0.7935\n",
      "Epoch 150/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0992 - accuracy: 0.9708 - val_loss: 1.0556 - val_accuracy: 0.8000\n",
      "Epoch 151/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0915 - accuracy: 0.9741 - val_loss: 1.0954 - val_accuracy: 0.8129\n",
      "Epoch 152/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1560 - accuracy: 0.9433 - val_loss: 1.0160 - val_accuracy: 0.7806\n",
      "Epoch 153/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1260 - accuracy: 0.9611 - val_loss: 0.9964 - val_accuracy: 0.7871\n",
      "Epoch 154/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0899 - accuracy: 0.9741 - val_loss: 1.0386 - val_accuracy: 0.7871\n",
      "Epoch 155/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1206 - accuracy: 0.9595 - val_loss: 1.0353 - val_accuracy: 0.7871\n",
      "Epoch 156/200\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.1275 - accuracy: 0.9562 - val_loss: 1.1023 - val_accuracy: 0.7935\n",
      "Epoch 157/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1553 - accuracy: 0.9514 - val_loss: 0.8775 - val_accuracy: 0.7484\n",
      "Epoch 158/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1735 - accuracy: 0.9303 - val_loss: 0.9279 - val_accuracy: 0.7935\n",
      "Epoch 159/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1157 - accuracy: 0.9611 - val_loss: 0.9231 - val_accuracy: 0.7935\n",
      "Epoch 160/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1013 - accuracy: 0.9741 - val_loss: 1.0333 - val_accuracy: 0.7935\n",
      "Epoch 161/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0895 - accuracy: 0.9660 - val_loss: 1.0656 - val_accuracy: 0.7935\n",
      "Epoch 162/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0889 - accuracy: 0.9789 - val_loss: 1.0934 - val_accuracy: 0.7871\n",
      "Epoch 163/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0879 - accuracy: 0.9773 - val_loss: 1.1457 - val_accuracy: 0.7677\n",
      "Epoch 164/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1091 - accuracy: 0.9643 - val_loss: 0.9501 - val_accuracy: 0.7935\n",
      "Epoch 165/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0906 - accuracy: 0.9692 - val_loss: 1.1664 - val_accuracy: 0.8000\n",
      "Epoch 166/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0762 - accuracy: 0.9822 - val_loss: 1.1636 - val_accuracy: 0.7935\n",
      "Epoch 167/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0635 - accuracy: 0.9806 - val_loss: 1.1952 - val_accuracy: 0.7871\n",
      "Epoch 168/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0666 - accuracy: 0.9838 - val_loss: 1.2621 - val_accuracy: 0.7742\n",
      "Epoch 169/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0718 - accuracy: 0.9757 - val_loss: 1.2209 - val_accuracy: 0.7806\n",
      "Epoch 170/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1048 - accuracy: 0.9676 - val_loss: 1.2314 - val_accuracy: 0.7871\n",
      "Epoch 171/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1084 - accuracy: 0.9595 - val_loss: 1.1190 - val_accuracy: 0.7871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0964 - accuracy: 0.9676 - val_loss: 1.1785 - val_accuracy: 0.7742\n",
      "Epoch 173/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0818 - accuracy: 0.9708 - val_loss: 1.3385 - val_accuracy: 0.7935\n",
      "Epoch 174/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0735 - accuracy: 0.9724 - val_loss: 1.1211 - val_accuracy: 0.7677\n",
      "Epoch 175/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1492 - accuracy: 0.9465 - val_loss: 1.0754 - val_accuracy: 0.8065\n",
      "Epoch 176/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1397 - accuracy: 0.9546 - val_loss: 1.0874 - val_accuracy: 0.7742\n",
      "Epoch 177/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0972 - accuracy: 0.9741 - val_loss: 1.2817 - val_accuracy: 0.7742\n",
      "Epoch 178/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1010 - accuracy: 0.9676 - val_loss: 1.2520 - val_accuracy: 0.7935\n",
      "Epoch 179/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0791 - accuracy: 0.9676 - val_loss: 1.1901 - val_accuracy: 0.7806\n",
      "Epoch 180/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0552 - accuracy: 0.9822 - val_loss: 1.3312 - val_accuracy: 0.7871\n",
      "Epoch 181/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0513 - accuracy: 0.9870 - val_loss: 1.3978 - val_accuracy: 0.7871\n",
      "Epoch 182/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0499 - accuracy: 0.9870 - val_loss: 1.4684 - val_accuracy: 0.7806\n",
      "Epoch 183/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0587 - accuracy: 0.9838 - val_loss: 1.4694 - val_accuracy: 0.7742\n",
      "Epoch 184/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0959 - accuracy: 0.9708 - val_loss: 1.3758 - val_accuracy: 0.7806\n",
      "Epoch 185/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0970 - accuracy: 0.9627 - val_loss: 1.4148 - val_accuracy: 0.7484\n",
      "Epoch 186/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0681 - accuracy: 0.9741 - val_loss: 1.3372 - val_accuracy: 0.7806\n",
      "Epoch 187/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1024 - accuracy: 0.9724 - val_loss: 1.2983 - val_accuracy: 0.7484\n",
      "Epoch 188/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1682 - accuracy: 0.9417 - val_loss: 1.0011 - val_accuracy: 0.7742\n",
      "Epoch 189/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2274 - accuracy: 0.9190 - val_loss: 0.9924 - val_accuracy: 0.7677\n",
      "Epoch 190/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2577 - accuracy: 0.9011 - val_loss: 0.8757 - val_accuracy: 0.7677\n",
      "Epoch 191/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1010 - accuracy: 0.9773 - val_loss: 0.8556 - val_accuracy: 0.7806\n",
      "Epoch 192/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0695 - accuracy: 0.9789 - val_loss: 0.9694 - val_accuracy: 0.7613\n",
      "Epoch 193/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0486 - accuracy: 0.9870 - val_loss: 1.1369 - val_accuracy: 0.7871\n",
      "Epoch 194/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0541 - accuracy: 0.9822 - val_loss: 1.1958 - val_accuracy: 0.7677\n",
      "Epoch 195/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0737 - accuracy: 0.9822 - val_loss: 1.1907 - val_accuracy: 0.7742\n",
      "Epoch 196/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1100 - accuracy: 0.9611 - val_loss: 1.0353 - val_accuracy: 0.7806\n",
      "Epoch 197/200\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.3103 - accuracy: 0.8979 - val_loss: 1.1377 - val_accuracy: 0.6645\n",
      "Epoch 198/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2508 - accuracy: 0.8979 - val_loss: 0.7612 - val_accuracy: 0.7935\n",
      "Epoch 199/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1647 - accuracy: 0.9384 - val_loss: 0.7816 - val_accuracy: 0.7742\n",
      "Epoch 200/200\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1031 - accuracy: 0.9643 - val_loss: 0.7231 - val_accuracy: 0.7935\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([train_x[:,:,0],train_x[:,:,1]], train_y,  epochs=200, validation_data=([valid_x[:,:,0],valid_x[:,:,1]], valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "f5cbace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8451613187789917\n",
      "Best epoch: 31\n"
     ]
    }
   ],
   "source": [
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "maxvalacc = max(val_acc_per_epoch)\n",
    "print(maxvalacc)\n",
    "best_epoch = val_acc_per_epoch.index(maxvalacc) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb36f74",
   "metadata": {},
   "source": [
    "## model tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "c66b0824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3d25d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    \n",
    "    visible1 = layers.Input(shape= (200,))\n",
    "    visible2 = layers.Input(shape= (200,))\n",
    "    embed_units = hp.Int('embed_units', min_value=10, max_value=20, step=2)\n",
    "    x1 = layers.Embedding(input_dim=vocabsize1, output_dim=embed_units)(visible1)\n",
    "    x2 = layers.Embedding(input_dim=vocabsize2, output_dim=embed_units)(visible2)\n",
    "    x = layers.Concatenate(axis = 2)([x1, x2])\n",
    "    rnn_units = hp.Int('rnn_units', min_value=10, max_value=40, step=3)\n",
    "    x = layers.Bidirectional(layers.LSTM(rnn_units, return_sequences=True))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(rnn_units))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    dense_units = hp.Int('dense_units', min_value=10, max_value=40, step=3)\n",
    "    x = layers.Dense(dense_units,activation='relu')(x)\n",
    "    output = layers.Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "9ec3f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='style_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "8cfde991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 14s]\n",
      "val_accuracy: 0.7870967984199524\n",
      "\n",
      "Best val_accuracy So Far: 0.8258064389228821\n",
      "Total elapsed time: 00h 05m 04s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. embeding units  18, rnn units  19, dense_units  34.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search([train_x[:,:,0],train_x[:,:,1]], train_y,  epochs=200, validation_data=([valid_x[:,:,0],valid_x[:,:,1]], valid_y))\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=2)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. embeding units  {best_hps.get('embed_units')}, rnn units  {best_hps.get('rnn_units')}, dense_units  {best_hps.get('dense_units')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8e1c686d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.6931 - accuracy: 0.5008 - val_loss: 0.6942 - val_accuracy: 0.4581\n",
      "Epoch 2/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.6930 - accuracy: 0.5186 - val_loss: 0.6957 - val_accuracy: 0.4581\n",
      "Epoch 3/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.6876 - accuracy: 0.5608 - val_loss: 0.6777 - val_accuracy: 0.6516\n",
      "Epoch 4/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.6016 - accuracy: 0.7261 - val_loss: 0.5195 - val_accuracy: 0.7677\n",
      "Epoch 5/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.6017 - accuracy: 0.7212 - val_loss: 0.5054 - val_accuracy: 0.7935\n",
      "Epoch 6/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.5633 - accuracy: 0.7423 - val_loss: 0.5238 - val_accuracy: 0.7742\n",
      "Epoch 7/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4958 - accuracy: 0.7909 - val_loss: 0.5088 - val_accuracy: 0.7806\n",
      "Epoch 8/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4760 - accuracy: 0.7990 - val_loss: 0.4970 - val_accuracy: 0.7935\n",
      "Epoch 9/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4612 - accuracy: 0.8136 - val_loss: 0.4638 - val_accuracy: 0.8000\n",
      "Epoch 10/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4349 - accuracy: 0.8104 - val_loss: 0.4348 - val_accuracy: 0.8065\n",
      "Epoch 11/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4348 - accuracy: 0.8169 - val_loss: 0.4497 - val_accuracy: 0.8000\n",
      "Epoch 12/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4399 - accuracy: 0.8250 - val_loss: 0.4364 - val_accuracy: 0.8194\n",
      "Epoch 13/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4073 - accuracy: 0.8395 - val_loss: 0.3992 - val_accuracy: 0.8323\n",
      "Epoch 14/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.3834 - accuracy: 0.8444 - val_loss: 0.4192 - val_accuracy: 0.8258\n",
      "Epoch 15/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4016 - accuracy: 0.8444 - val_loss: 0.3831 - val_accuracy: 0.8452\n",
      "Epoch 16/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.3766 - accuracy: 0.8395 - val_loss: 0.3732 - val_accuracy: 0.8581\n",
      "Epoch 17/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.3776 - accuracy: 0.8444 - val_loss: 0.4134 - val_accuracy: 0.8000\n",
      "Epoch 18/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.3668 - accuracy: 0.8509 - val_loss: 0.3643 - val_accuracy: 0.8387\n",
      "Epoch 19/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3489 - accuracy: 0.8558 - val_loss: 0.3499 - val_accuracy: 0.8387\n",
      "Epoch 20/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.3507 - accuracy: 0.8606 - val_loss: 0.3552 - val_accuracy: 0.8258\n",
      "Epoch 21/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3492 - accuracy: 0.8574 - val_loss: 0.4352 - val_accuracy: 0.8194\n",
      "Epoch 22/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4037 - accuracy: 0.8314 - val_loss: 0.3491 - val_accuracy: 0.8323\n",
      "Epoch 23/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3267 - accuracy: 0.8687 - val_loss: 0.3634 - val_accuracy: 0.8452\n",
      "Epoch 24/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3517 - accuracy: 0.8590 - val_loss: 0.3632 - val_accuracy: 0.8323\n",
      "Epoch 25/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3330 - accuracy: 0.8671 - val_loss: 0.4123 - val_accuracy: 0.8194\n",
      "Epoch 26/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3370 - accuracy: 0.8639 - val_loss: 0.4574 - val_accuracy: 0.7935\n",
      "Epoch 27/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3789 - accuracy: 0.8590 - val_loss: 0.4244 - val_accuracy: 0.8323\n",
      "Epoch 28/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3463 - accuracy: 0.8655 - val_loss: 0.4085 - val_accuracy: 0.8194\n",
      "Epoch 29/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3428 - accuracy: 0.8574 - val_loss: 0.4004 - val_accuracy: 0.8452\n",
      "Epoch 30/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2991 - accuracy: 0.8736 - val_loss: 0.3817 - val_accuracy: 0.8323\n",
      "Epoch 31/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3236 - accuracy: 0.8671 - val_loss: 0.3836 - val_accuracy: 0.8323\n",
      "Epoch 32/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2897 - accuracy: 0.8865 - val_loss: 0.3882 - val_accuracy: 0.8323\n",
      "Epoch 33/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2983 - accuracy: 0.8639 - val_loss: 0.4043 - val_accuracy: 0.8258\n",
      "Epoch 34/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.2828 - accuracy: 0.8801 - val_loss: 0.5587 - val_accuracy: 0.7935\n",
      "Epoch 35/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3448 - accuracy: 0.8606 - val_loss: 0.4184 - val_accuracy: 0.8516\n",
      "Epoch 36/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2829 - accuracy: 0.8898 - val_loss: 0.4918 - val_accuracy: 0.7871\n",
      "Epoch 37/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4454 - accuracy: 0.7828 - val_loss: 0.4962 - val_accuracy: 0.7548\n",
      "Epoch 38/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.3243 - accuracy: 0.8671 - val_loss: 0.5527 - val_accuracy: 0.7806\n",
      "Epoch 39/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.3122 - accuracy: 0.8784 - val_loss: 0.4443 - val_accuracy: 0.8258\n",
      "Epoch 40/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2804 - accuracy: 0.8898 - val_loss: 0.4601 - val_accuracy: 0.8258\n",
      "Epoch 41/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2876 - accuracy: 0.8752 - val_loss: 0.4693 - val_accuracy: 0.8065\n",
      "Epoch 42/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2598 - accuracy: 0.8882 - val_loss: 0.5009 - val_accuracy: 0.8065\n",
      "Epoch 43/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.2622 - accuracy: 0.8833 - val_loss: 0.5205 - val_accuracy: 0.7806\n",
      "Epoch 44/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.3057 - accuracy: 0.8736 - val_loss: 0.5383 - val_accuracy: 0.8065\n",
      "Epoch 45/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.3099 - accuracy: 0.8590 - val_loss: 0.4449 - val_accuracy: 0.8065\n",
      "Epoch 46/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2761 - accuracy: 0.8979 - val_loss: 0.5598 - val_accuracy: 0.8323\n",
      "Epoch 47/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2592 - accuracy: 0.8963 - val_loss: 0.5697 - val_accuracy: 0.8194\n",
      "Epoch 48/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.3281 - accuracy: 0.8752 - val_loss: 0.4606 - val_accuracy: 0.8323\n",
      "Epoch 49/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2984 - accuracy: 0.8865 - val_loss: 0.4570 - val_accuracy: 0.8065\n",
      "Epoch 50/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2579 - accuracy: 0.8979 - val_loss: 0.5111 - val_accuracy: 0.7806\n",
      "Epoch 51/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2627 - accuracy: 0.8995 - val_loss: 0.5164 - val_accuracy: 0.7935\n",
      "Epoch 52/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2431 - accuracy: 0.8947 - val_loss: 0.4966 - val_accuracy: 0.8194\n",
      "Epoch 53/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2564 - accuracy: 0.8865 - val_loss: 0.5461 - val_accuracy: 0.8000\n",
      "Epoch 54/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2739 - accuracy: 0.8914 - val_loss: 0.6052 - val_accuracy: 0.8000\n",
      "Epoch 55/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2681 - accuracy: 0.8882 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 56/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2426 - accuracy: 0.9060 - val_loss: 0.6162 - val_accuracy: 0.7871\n",
      "Epoch 57/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2545 - accuracy: 0.9044 - val_loss: 0.6513 - val_accuracy: 0.7613\n",
      "Epoch 58/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2868 - accuracy: 0.8849 - val_loss: 0.5010 - val_accuracy: 0.8000\n",
      "Epoch 59/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2695 - accuracy: 0.8882 - val_loss: 0.6157 - val_accuracy: 0.7871\n",
      "Epoch 60/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2208 - accuracy: 0.9109 - val_loss: 0.5399 - val_accuracy: 0.7613\n",
      "Epoch 61/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2319 - accuracy: 0.9092 - val_loss: 0.6390 - val_accuracy: 0.7935\n",
      "Epoch 62/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2640 - accuracy: 0.8963 - val_loss: 0.6035 - val_accuracy: 0.7613\n",
      "Epoch 63/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2323 - accuracy: 0.9125 - val_loss: 0.5851 - val_accuracy: 0.7806\n",
      "Epoch 64/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2098 - accuracy: 0.9222 - val_loss: 0.6757 - val_accuracy: 0.8000\n",
      "Epoch 65/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2445 - accuracy: 0.9092 - val_loss: 0.7889 - val_accuracy: 0.8194\n",
      "Epoch 66/200\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2703 - accuracy: 0.8784 - val_loss: 0.5496 - val_accuracy: 0.7935\n",
      "Epoch 67/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2180 - accuracy: 0.9173 - val_loss: 0.6774 - val_accuracy: 0.7677\n",
      "Epoch 68/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2257 - accuracy: 0.9011 - val_loss: 0.6163 - val_accuracy: 0.8000\n",
      "Epoch 69/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2159 - accuracy: 0.9125 - val_loss: 0.6346 - val_accuracy: 0.7677\n",
      "Epoch 70/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2106 - accuracy: 0.9125 - val_loss: 0.6432 - val_accuracy: 0.7742\n",
      "Epoch 71/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.3729 - accuracy: 0.8347 - val_loss: 0.5112 - val_accuracy: 0.7613\n",
      "Epoch 72/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2770 - accuracy: 0.8865 - val_loss: 0.8382 - val_accuracy: 0.8000\n",
      "Epoch 73/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2616 - accuracy: 0.8979 - val_loss: 0.5477 - val_accuracy: 0.7419\n",
      "Epoch 74/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2815 - accuracy: 0.8817 - val_loss: 0.5589 - val_accuracy: 0.7935\n",
      "Epoch 75/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2105 - accuracy: 0.9141 - val_loss: 0.5799 - val_accuracy: 0.7806\n",
      "Epoch 76/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2117 - accuracy: 0.9222 - val_loss: 0.7154 - val_accuracy: 0.7742\n",
      "Epoch 77/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2015 - accuracy: 0.9190 - val_loss: 0.6199 - val_accuracy: 0.8000\n",
      "Epoch 78/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2020 - accuracy: 0.9271 - val_loss: 0.6987 - val_accuracy: 0.7871\n",
      "Epoch 79/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2071 - accuracy: 0.9222 - val_loss: 0.6763 - val_accuracy: 0.7871\n",
      "Epoch 80/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2146 - accuracy: 0.9238 - val_loss: 0.8817 - val_accuracy: 0.7613\n",
      "Epoch 81/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2208 - accuracy: 0.9125 - val_loss: 0.6573 - val_accuracy: 0.7806\n",
      "Epoch 82/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1854 - accuracy: 0.9271 - val_loss: 0.7320 - val_accuracy: 0.7613\n",
      "Epoch 83/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1890 - accuracy: 0.9303 - val_loss: 0.8791 - val_accuracy: 0.7677\n",
      "Epoch 84/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2526 - accuracy: 0.8865 - val_loss: 0.6734 - val_accuracy: 0.7935\n",
      "Epoch 85/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1908 - accuracy: 0.9303 - val_loss: 0.6555 - val_accuracy: 0.8129\n",
      "Epoch 86/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1755 - accuracy: 0.9319 - val_loss: 0.6655 - val_accuracy: 0.7871\n",
      "Epoch 87/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.3277 - accuracy: 0.8687 - val_loss: 0.5894 - val_accuracy: 0.7871\n",
      "Epoch 88/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2341 - accuracy: 0.9060 - val_loss: 0.6555 - val_accuracy: 0.7806\n",
      "Epoch 89/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1993 - accuracy: 0.9319 - val_loss: 0.7064 - val_accuracy: 0.7742\n",
      "Epoch 90/200\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2118 - accuracy: 0.9157 - val_loss: 0.7388 - val_accuracy: 0.7677\n",
      "Epoch 91/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2168 - accuracy: 0.9092 - val_loss: 0.6693 - val_accuracy: 0.8000\n",
      "Epoch 92/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1819 - accuracy: 0.9303 - val_loss: 0.6945 - val_accuracy: 0.8000\n",
      "Epoch 93/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1702 - accuracy: 0.9352 - val_loss: 0.7629 - val_accuracy: 0.7935\n",
      "Epoch 94/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1817 - accuracy: 0.9287 - val_loss: 0.9224 - val_accuracy: 0.7677\n",
      "Epoch 95/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1814 - accuracy: 0.9368 - val_loss: 0.7323 - val_accuracy: 0.7677\n",
      "Epoch 96/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2059 - accuracy: 0.9141 - val_loss: 0.8164 - val_accuracy: 0.7613\n",
      "Epoch 97/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1706 - accuracy: 0.9303 - val_loss: 0.7412 - val_accuracy: 0.7871\n",
      "Epoch 98/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1666 - accuracy: 0.9417 - val_loss: 0.8448 - val_accuracy: 0.7677\n",
      "Epoch 99/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1637 - accuracy: 0.9400 - val_loss: 0.8184 - val_accuracy: 0.8000\n",
      "Epoch 100/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1658 - accuracy: 0.9417 - val_loss: 0.8798 - val_accuracy: 0.7806\n",
      "Epoch 101/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1983 - accuracy: 0.9190 - val_loss: 0.9793 - val_accuracy: 0.7677\n",
      "Epoch 102/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1707 - accuracy: 0.9335 - val_loss: 0.8267 - val_accuracy: 0.7806\n",
      "Epoch 103/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1903 - accuracy: 0.9271 - val_loss: 0.7598 - val_accuracy: 0.7935\n",
      "Epoch 104/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1821 - accuracy: 0.9368 - val_loss: 0.7970 - val_accuracy: 0.7742\n",
      "Epoch 105/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1912 - accuracy: 0.9271 - val_loss: 0.7884 - val_accuracy: 0.7677\n",
      "Epoch 106/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1767 - accuracy: 0.9254 - val_loss: 0.9147 - val_accuracy: 0.7935\n",
      "Epoch 107/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1879 - accuracy: 0.9206 - val_loss: 0.7076 - val_accuracy: 0.7806\n",
      "Epoch 108/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1825 - accuracy: 0.9384 - val_loss: 0.8651 - val_accuracy: 0.7484\n",
      "Epoch 109/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1496 - accuracy: 0.9384 - val_loss: 0.9198 - val_accuracy: 0.7935\n",
      "Epoch 110/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1959 - accuracy: 0.9173 - val_loss: 0.8576 - val_accuracy: 0.7161\n",
      "Epoch 111/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1919 - accuracy: 0.9222 - val_loss: 0.7435 - val_accuracy: 0.7484\n",
      "Epoch 112/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2235 - accuracy: 0.9060 - val_loss: 1.0041 - val_accuracy: 0.7871\n",
      "Epoch 113/200\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1835 - accuracy: 0.9271 - val_loss: 0.7655 - val_accuracy: 0.7871\n",
      "Epoch 114/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1682 - accuracy: 0.9417 - val_loss: 0.7701 - val_accuracy: 0.7677\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2328 - accuracy: 0.9060 - val_loss: 0.6548 - val_accuracy: 0.7742\n",
      "Epoch 116/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1673 - accuracy: 0.9335 - val_loss: 0.8637 - val_accuracy: 0.7935\n",
      "Epoch 117/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1423 - accuracy: 0.9465 - val_loss: 0.9023 - val_accuracy: 0.7742\n",
      "Epoch 118/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1321 - accuracy: 0.9465 - val_loss: 0.8946 - val_accuracy: 0.7677\n",
      "Epoch 119/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1795 - accuracy: 0.9222 - val_loss: 0.8595 - val_accuracy: 0.7935\n",
      "Epoch 120/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.3475 - accuracy: 0.8574 - val_loss: 0.9420 - val_accuracy: 0.6452\n",
      "Epoch 121/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2780 - accuracy: 0.8752 - val_loss: 0.7692 - val_accuracy: 0.7871\n",
      "Epoch 122/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1722 - accuracy: 0.9303 - val_loss: 0.8297 - val_accuracy: 0.7806\n",
      "Epoch 123/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1443 - accuracy: 0.9498 - val_loss: 0.9153 - val_accuracy: 0.7742\n",
      "Epoch 124/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1477 - accuracy: 0.9433 - val_loss: 0.9780 - val_accuracy: 0.7742\n",
      "Epoch 125/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2035 - accuracy: 0.9238 - val_loss: 0.8135 - val_accuracy: 0.7484\n",
      "Epoch 126/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1422 - accuracy: 0.9417 - val_loss: 0.8974 - val_accuracy: 0.7290\n",
      "Epoch 127/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1623 - accuracy: 0.9335 - val_loss: 0.9650 - val_accuracy: 0.7613\n",
      "Epoch 128/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1291 - accuracy: 0.9530 - val_loss: 0.9497 - val_accuracy: 0.7742\n",
      "Epoch 129/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1303 - accuracy: 0.9530 - val_loss: 1.1120 - val_accuracy: 0.7742\n",
      "Epoch 130/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1274 - accuracy: 0.9611 - val_loss: 1.1052 - val_accuracy: 0.7742\n",
      "Epoch 131/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2176 - accuracy: 0.9076 - val_loss: 0.8829 - val_accuracy: 0.6968\n",
      "Epoch 132/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1994 - accuracy: 0.9287 - val_loss: 0.8528 - val_accuracy: 0.7484\n",
      "Epoch 133/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2217 - accuracy: 0.9109 - val_loss: 0.8171 - val_accuracy: 0.7806\n",
      "Epoch 134/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1842 - accuracy: 0.9287 - val_loss: 0.9185 - val_accuracy: 0.7548\n",
      "Epoch 135/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1292 - accuracy: 0.9595 - val_loss: 0.8904 - val_accuracy: 0.7548\n",
      "Epoch 136/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1131 - accuracy: 0.9627 - val_loss: 0.9070 - val_accuracy: 0.7742\n",
      "Epoch 137/200\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1298 - accuracy: 0.9546 - val_loss: 1.0017 - val_accuracy: 0.7613\n",
      "Epoch 138/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1176 - accuracy: 0.9643 - val_loss: 0.9004 - val_accuracy: 0.7355\n",
      "Epoch 139/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1104 - accuracy: 0.9611 - val_loss: 1.0450 - val_accuracy: 0.7613\n",
      "Epoch 140/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2642 - accuracy: 0.9028 - val_loss: 0.8851 - val_accuracy: 0.7935\n",
      "Epoch 141/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1389 - accuracy: 0.9449 - val_loss: 0.9214 - val_accuracy: 0.7742\n",
      "Epoch 142/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1127 - accuracy: 0.9611 - val_loss: 1.1201 - val_accuracy: 0.7613\n",
      "Epoch 143/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1075 - accuracy: 0.9611 - val_loss: 1.1228 - val_accuracy: 0.7548\n",
      "Epoch 144/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1153 - accuracy: 0.9627 - val_loss: 1.2140 - val_accuracy: 0.7742\n",
      "Epoch 145/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1218 - accuracy: 0.9498 - val_loss: 1.0410 - val_accuracy: 0.7548\n",
      "Epoch 146/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1952 - accuracy: 0.9254 - val_loss: 1.2833 - val_accuracy: 0.7032\n",
      "Epoch 147/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2471 - accuracy: 0.8914 - val_loss: 1.3351 - val_accuracy: 0.7290\n",
      "Epoch 148/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1849 - accuracy: 0.9335 - val_loss: 0.9122 - val_accuracy: 0.7806\n",
      "Epoch 149/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1093 - accuracy: 0.9643 - val_loss: 0.9933 - val_accuracy: 0.7484\n",
      "Epoch 150/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0913 - accuracy: 0.9724 - val_loss: 1.0933 - val_accuracy: 0.7871\n",
      "Epoch 151/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1239 - accuracy: 0.9498 - val_loss: 1.1144 - val_accuracy: 0.7548\n",
      "Epoch 152/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2069 - accuracy: 0.9335 - val_loss: 1.1270 - val_accuracy: 0.7226\n",
      "Epoch 153/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1605 - accuracy: 0.9481 - val_loss: 1.1096 - val_accuracy: 0.7613\n",
      "Epoch 154/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0991 - accuracy: 0.9724 - val_loss: 1.1278 - val_accuracy: 0.7548\n",
      "Epoch 155/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1127 - accuracy: 0.9611 - val_loss: 1.1235 - val_accuracy: 0.7677\n",
      "Epoch 156/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0988 - accuracy: 0.9724 - val_loss: 1.1190 - val_accuracy: 0.7484\n",
      "Epoch 157/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1119 - accuracy: 0.9595 - val_loss: 1.3224 - val_accuracy: 0.7290\n",
      "Epoch 158/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0853 - accuracy: 0.9692 - val_loss: 1.0822 - val_accuracy: 0.7871\n",
      "Epoch 159/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0600 - accuracy: 0.9919 - val_loss: 1.2344 - val_accuracy: 0.7548\n",
      "Epoch 160/200\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0467 - accuracy: 0.9935 - val_loss: 1.3886 - val_accuracy: 0.7677\n",
      "Epoch 161/200\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0701 - accuracy: 0.9822 - val_loss: 1.2628 - val_accuracy: 0.7677\n",
      "Epoch 162/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0530 - accuracy: 0.9887 - val_loss: 1.3874 - val_accuracy: 0.7419\n",
      "Epoch 163/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0741 - accuracy: 0.9773 - val_loss: 1.1625 - val_accuracy: 0.7871\n",
      "Epoch 164/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2954 - accuracy: 0.9028 - val_loss: 1.2039 - val_accuracy: 0.6903\n",
      "Epoch 165/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2448 - accuracy: 0.9157 - val_loss: 1.0293 - val_accuracy: 0.7613\n",
      "Epoch 166/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1147 - accuracy: 0.9611 - val_loss: 0.9126 - val_accuracy: 0.7677\n",
      "Epoch 167/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0782 - accuracy: 0.9822 - val_loss: 1.0788 - val_accuracy: 0.7806\n",
      "Epoch 168/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0584 - accuracy: 0.9822 - val_loss: 1.1362 - val_accuracy: 0.7613\n",
      "Epoch 169/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0521 - accuracy: 0.9919 - val_loss: 1.3152 - val_accuracy: 0.7806\n",
      "Epoch 170/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0951 - accuracy: 0.9724 - val_loss: 1.2466 - val_accuracy: 0.7419\n",
      "Epoch 171/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1526 - accuracy: 0.9579 - val_loss: 1.2735 - val_accuracy: 0.7355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1116 - accuracy: 0.9660 - val_loss: 0.9722 - val_accuracy: 0.7871\n",
      "Epoch 173/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0711 - accuracy: 0.9838 - val_loss: 1.1632 - val_accuracy: 0.7548\n",
      "Epoch 174/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0770 - accuracy: 0.9822 - val_loss: 1.3404 - val_accuracy: 0.7484\n",
      "Epoch 175/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.3061 - accuracy: 0.8849 - val_loss: 0.9754 - val_accuracy: 0.6968\n",
      "Epoch 176/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1446 - accuracy: 0.9449 - val_loss: 0.9398 - val_accuracy: 0.7548\n",
      "Epoch 177/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1716 - accuracy: 0.9368 - val_loss: 0.9732 - val_accuracy: 0.7613\n",
      "Epoch 178/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0911 - accuracy: 0.9724 - val_loss: 0.9895 - val_accuracy: 0.7806\n",
      "Epoch 179/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0661 - accuracy: 0.9806 - val_loss: 1.2247 - val_accuracy: 0.7613\n",
      "Epoch 180/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0893 - accuracy: 0.9757 - val_loss: 1.0288 - val_accuracy: 0.7677\n",
      "Epoch 181/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0800 - accuracy: 0.9757 - val_loss: 1.2185 - val_accuracy: 0.7290\n",
      "Epoch 182/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0734 - accuracy: 0.9822 - val_loss: 1.1793 - val_accuracy: 0.7419\n",
      "Epoch 183/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0464 - accuracy: 0.9919 - val_loss: 1.2476 - val_accuracy: 0.7677\n",
      "Epoch 184/200\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0454 - accuracy: 0.9919 - val_loss: 1.2418 - val_accuracy: 0.7419\n",
      "Epoch 185/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0530 - accuracy: 0.9903 - val_loss: 1.2409 - val_accuracy: 0.7355\n",
      "Epoch 186/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1526 - accuracy: 0.9433 - val_loss: 1.3441 - val_accuracy: 0.7032\n",
      "Epoch 187/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1139 - accuracy: 0.9660 - val_loss: 1.2548 - val_accuracy: 0.7355\n",
      "Epoch 188/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0737 - accuracy: 0.9724 - val_loss: 1.1961 - val_accuracy: 0.7226\n",
      "Epoch 189/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0539 - accuracy: 0.9903 - val_loss: 1.2745 - val_accuracy: 0.7484\n",
      "Epoch 190/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0481 - accuracy: 0.9887 - val_loss: 1.3957 - val_accuracy: 0.7419\n",
      "Epoch 191/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0512 - accuracy: 0.9903 - val_loss: 1.5382 - val_accuracy: 0.7355\n",
      "Epoch 192/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0752 - accuracy: 0.9757 - val_loss: 1.2409 - val_accuracy: 0.7419\n",
      "Epoch 193/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0466 - accuracy: 0.9919 - val_loss: 1.4555 - val_accuracy: 0.7677\n",
      "Epoch 194/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0730 - accuracy: 0.9870 - val_loss: 1.3438 - val_accuracy: 0.7742\n",
      "Epoch 195/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0672 - accuracy: 0.9806 - val_loss: 1.4771 - val_accuracy: 0.7484\n",
      "Epoch 196/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0571 - accuracy: 0.9870 - val_loss: 1.5100 - val_accuracy: 0.7548\n",
      "Epoch 197/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1400 - accuracy: 0.9660 - val_loss: 1.1676 - val_accuracy: 0.7290\n",
      "Epoch 198/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1374 - accuracy: 0.9530 - val_loss: 1.1809 - val_accuracy: 0.7484\n",
      "Epoch 199/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0988 - accuracy: 0.9676 - val_loss: 1.2549 - val_accuracy: 0.7613\n",
      "Epoch 200/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0507 - accuracy: 0.9919 - val_loss: 1.1968 - val_accuracy: 0.7613\n",
      "Best epoch: 16\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit([train_x[:,:,0],train_x[:,:,1]], train_y, epochs=200, validation_data=([valid_x[:,:,0],valid_x[:,:,1]],valid_y))\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "71e14a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'classifiers/temp'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "5a399d2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.6929 - accuracy: 0.4753INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "20/20 [==============================] - 20s 999ms/step - loss: 0.6928 - accuracy: 0.4765 - val_loss: 0.6941 - val_accuracy: 0.4839\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.6921 - accuracy: 0.5251 - val_loss: 0.6936 - val_accuracy: 0.4839\n",
      "Epoch 3/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.6877 - accuracy: 0.5477INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "20/20 [==============================] - 19s 944ms/step - loss: 0.6880 - accuracy: 0.5462 - val_loss: 0.6832 - val_accuracy: 0.6645\n",
      "Epoch 4/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.6751 - accuracy: 0.5921INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "20/20 [==============================] - 20s 1s/step - loss: 0.6738 - accuracy: 0.5964 - val_loss: 0.6371 - val_accuracy: 0.6774\n",
      "Epoch 5/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.5560 - accuracy: 0.7434INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "20/20 [==============================] - 20s 991ms/step - loss: 0.5545 - accuracy: 0.7439 - val_loss: 0.6104 - val_accuracy: 0.7161\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.6095 - accuracy: 0.6661 - val_loss: 0.5862 - val_accuracy: 0.6968\n",
      "Epoch 7/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.5521 - accuracy: 0.7434INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "20/20 [==============================] - 19s 956ms/step - loss: 0.5560 - accuracy: 0.7407 - val_loss: 0.5433 - val_accuracy: 0.7355\n",
      "Epoch 8/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.4988 - accuracy: 0.7780INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "20/20 [==============================] - 20s 1s/step - loss: 0.5041 - accuracy: 0.7731 - val_loss: 0.5320 - val_accuracy: 0.7419\n",
      "Epoch 9/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.4911 - accuracy: 0.7812INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "20/20 [==============================] - 20s 986ms/step - loss: 0.4894 - accuracy: 0.7828 - val_loss: 0.5036 - val_accuracy: 0.7548\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4624 - accuracy: 0.7925 - val_loss: 0.5030 - val_accuracy: 0.7419\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4463 - accuracy: 0.7942 - val_loss: 0.5016 - val_accuracy: 0.7484\n",
      "Epoch 12/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.4197 - accuracy: 0.8141INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "20/20 [==============================] - 18s 913ms/step - loss: 0.4209 - accuracy: 0.8120 - val_loss: 0.4729 - val_accuracy: 0.7806\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3947 - accuracy: 0.8347 - val_loss: 0.4617 - val_accuracy: 0.7806\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.3957 - accuracy: 0.8347 - val_loss: 0.4521 - val_accuracy: 0.7806\n",
      "Epoch 15/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.3811 - accuracy: 0.8405INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "20/20 [==============================] - 21s 1s/step - loss: 0.3802 - accuracy: 0.8412 - val_loss: 0.4959 - val_accuracy: 0.7935\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3812 - accuracy: 0.8412 - val_loss: 0.4272 - val_accuracy: 0.7935\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.3491 - accuracy: 0.8574 - val_loss: 0.4914 - val_accuracy: 0.7613\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.3846 - accuracy: 0.8428 - val_loss: 0.5050 - val_accuracy: 0.7871\n",
      "Epoch 19/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.3698 - accuracy: 0.8553INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "20/20 [==============================] - 20s 978ms/step - loss: 0.3677 - accuracy: 0.8558 - val_loss: 0.4377 - val_accuracy: 0.8129\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3762 - accuracy: 0.8525 - val_loss: 0.4223 - val_accuracy: 0.7677\n",
      "Epoch 21/100\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.3535 - accuracy: 0.8520INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "20/20 [==============================] - 19s 962ms/step - loss: 0.3519 - accuracy: 0.8525 - val_loss: 0.4388 - val_accuracy: 0.8258\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3187 - accuracy: 0.8687 - val_loss: 0.4897 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.3744 - accuracy: 0.8444 - val_loss: 0.4116 - val_accuracy: 0.8129\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.3326 - accuracy: 0.8590 - val_loss: 0.4214 - val_accuracy: 0.8065\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3179 - accuracy: 0.8720 - val_loss: 0.4154 - val_accuracy: 0.8194\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2915 - accuracy: 0.8801 - val_loss: 0.5598 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.3010 - accuracy: 0.8882 - val_loss: 0.4302 - val_accuracy: 0.7613\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.3154 - accuracy: 0.8849 - val_loss: 0.4289 - val_accuracy: 0.8258\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.3546 - accuracy: 0.8476 - val_loss: 0.5613 - val_accuracy: 0.7806\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.3925 - accuracy: 0.8266 - val_loss: 0.4419 - val_accuracy: 0.8258\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.3049 - accuracy: 0.8914 - val_loss: 0.4756 - val_accuracy: 0.8194\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2947 - accuracy: 0.8833 - val_loss: 0.4545 - val_accuracy: 0.7742\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.2864 - accuracy: 0.8849 - val_loss: 0.5253 - val_accuracy: 0.8194\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2878 - accuracy: 0.8720 - val_loss: 0.5380 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.3115 - accuracy: 0.8768 - val_loss: 0.4548 - val_accuracy: 0.7806\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2860 - accuracy: 0.8817 - val_loss: 0.5239 - val_accuracy: 0.8065\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.2930 - accuracy: 0.8930 - val_loss: 0.5095 - val_accuracy: 0.7742\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.2919 - accuracy: 0.8752 - val_loss: 0.4971 - val_accuracy: 0.7871\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2785 - accuracy: 0.8882 - val_loss: 0.4707 - val_accuracy: 0.7935\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2794 - accuracy: 0.8898 - val_loss: 0.4472 - val_accuracy: 0.7871\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2628 - accuracy: 0.8784 - val_loss: 0.5494 - val_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.3066 - accuracy: 0.8703 - val_loss: 0.5201 - val_accuracy: 0.7290\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.3058 - accuracy: 0.8687 - val_loss: 0.5384 - val_accuracy: 0.8194\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2468 - accuracy: 0.8995 - val_loss: 0.5036 - val_accuracy: 0.7806\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2695 - accuracy: 0.8947 - val_loss: 0.5652 - val_accuracy: 0.8129\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2886 - accuracy: 0.8801 - val_loss: 0.5886 - val_accuracy: 0.7677\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.2686 - accuracy: 0.8930 - val_loss: 0.5332 - val_accuracy: 0.7806\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.2762 - accuracy: 0.8849 - val_loss: 0.5576 - val_accuracy: 0.8194\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2592 - accuracy: 0.9076 - val_loss: 0.5537 - val_accuracy: 0.7742\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2363 - accuracy: 0.9076 - val_loss: 0.5625 - val_accuracy: 0.7742\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2379 - accuracy: 0.9011 - val_loss: 0.6014 - val_accuracy: 0.8065\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2468 - accuracy: 0.8979 - val_loss: 0.5529 - val_accuracy: 0.7484\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2300 - accuracy: 0.9028 - val_loss: 0.6245 - val_accuracy: 0.7742\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2266 - accuracy: 0.8979 - val_loss: 0.6710 - val_accuracy: 0.7935\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2489 - accuracy: 0.8882 - val_loss: 0.5545 - val_accuracy: 0.7742\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.2349 - accuracy: 0.9011 - val_loss: 0.7038 - val_accuracy: 0.7161\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2332 - accuracy: 0.9125 - val_loss: 0.5775 - val_accuracy: 0.7548\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2548 - accuracy: 0.9092 - val_loss: 0.6779 - val_accuracy: 0.7226\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2068 - accuracy: 0.9125 - val_loss: 0.6416 - val_accuracy: 0.7677\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2070 - accuracy: 0.9352 - val_loss: 0.6683 - val_accuracy: 0.7548\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2000 - accuracy: 0.9238 - val_loss: 0.6332 - val_accuracy: 0.7742\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.2393 - accuracy: 0.8930 - val_loss: 0.6320 - val_accuracy: 0.7419\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2101 - accuracy: 0.9109 - val_loss: 0.6654 - val_accuracy: 0.7742\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1758 - accuracy: 0.9303 - val_loss: 0.6980 - val_accuracy: 0.7613\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1796 - accuracy: 0.9368 - val_loss: 0.8275 - val_accuracy: 0.7613\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1942 - accuracy: 0.9287 - val_loss: 0.6497 - val_accuracy: 0.7742\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1852 - accuracy: 0.9271 - val_loss: 0.7137 - val_accuracy: 0.7677\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2117 - accuracy: 0.9238 - val_loss: 0.6923 - val_accuracy: 0.7613\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1626 - accuracy: 0.9514 - val_loss: 0.6979 - val_accuracy: 0.7806\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1829 - accuracy: 0.9433 - val_loss: 0.6848 - val_accuracy: 0.7677\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.1432 - accuracy: 0.9546 - val_loss: 1.0009 - val_accuracy: 0.7161\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2175 - accuracy: 0.9173 - val_loss: 0.7486 - val_accuracy: 0.7484\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2061 - accuracy: 0.9222 - val_loss: 0.8178 - val_accuracy: 0.7548\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.5931 - accuracy: 0.7293 - val_loss: 0.6677 - val_accuracy: 0.6194\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.3283 - accuracy: 0.8622 - val_loss: 0.5630 - val_accuracy: 0.8129\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.2453 - accuracy: 0.9076 - val_loss: 0.6168 - val_accuracy: 0.7871\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1985 - accuracy: 0.9287 - val_loss: 0.6334 - val_accuracy: 0.7871\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1935 - accuracy: 0.9254 - val_loss: 0.6595 - val_accuracy: 0.7871\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1610 - accuracy: 0.9384 - val_loss: 0.6902 - val_accuracy: 0.7742\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2652 - accuracy: 0.9011 - val_loss: 0.8803 - val_accuracy: 0.7742\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1892 - accuracy: 0.9190 - val_loss: 0.6691 - val_accuracy: 0.7613\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1581 - accuracy: 0.9465 - val_loss: 0.6786 - val_accuracy: 0.7677\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1746 - accuracy: 0.9303 - val_loss: 0.7793 - val_accuracy: 0.7871\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1368 - accuracy: 0.9498 - val_loss: 0.8398 - val_accuracy: 0.7484\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1151 - accuracy: 0.9643 - val_loss: 0.9639 - val_accuracy: 0.7484\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1049 - accuracy: 0.9643 - val_loss: 0.9261 - val_accuracy: 0.7806\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1959 - accuracy: 0.9400 - val_loss: 0.7591 - val_accuracy: 0.8065\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1521 - accuracy: 0.9498 - val_loss: 0.7951 - val_accuracy: 0.7677\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1622 - accuracy: 0.9352 - val_loss: 0.8772 - val_accuracy: 0.7355\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1419 - accuracy: 0.9449 - val_loss: 0.7887 - val_accuracy: 0.7742\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1210 - accuracy: 0.9579 - val_loss: 0.8750 - val_accuracy: 0.7677\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1491 - accuracy: 0.9417 - val_loss: 0.8982 - val_accuracy: 0.7742\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.1081 - accuracy: 0.9611 - val_loss: 0.9467 - val_accuracy: 0.7742\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0972 - accuracy: 0.9757 - val_loss: 0.9230 - val_accuracy: 0.7613\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0962 - accuracy: 0.9708 - val_loss: 1.0012 - val_accuracy: 0.7548\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1345 - accuracy: 0.9514 - val_loss: 0.9865 - val_accuracy: 0.7548\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1075 - accuracy: 0.9660 - val_loss: 0.9354 - val_accuracy: 0.7935\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1189 - accuracy: 0.9546 - val_loss: 1.0054 - val_accuracy: 0.7742\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2240 - accuracy: 0.9060 - val_loss: 0.7336 - val_accuracy: 0.7806\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1365 - accuracy: 0.9514 - val_loss: 0.8123 - val_accuracy: 0.7677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2416fa31550>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "hypermodel.fit([train_x[:,:,0],train_x[:,:,1]], train_y, epochs=100, validation_data=([valid_x[:,:,0],valid_x[:,:,1]],valid_y), callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "6705b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a1b33cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x241367fc940>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(np.argmax(test_y, axis = 1), np.argmax(model.predict([test_x[:,:,0], test_x[:,:,1]]), axis = 1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "0711064c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81        86\n",
      "           1       0.86      0.81      0.84       107\n",
      "\n",
      "    accuracy                           0.82       193\n",
      "   macro avg       0.82      0.83      0.82       193\n",
      "weighted avg       0.83      0.82      0.82       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(np.argmax(test_y, axis = 1), np.argmax(model.predict([test_x[:,:,0], test_x[:,:,1]]), axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11456a24",
   "metadata": {},
   "source": [
    "## train final model on test and validation datasets and validate on test data_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f26e68c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'classifiers/temp'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "10e6797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.4806INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "25/25 [==============================] - 19s 740ms/step - loss: 0.6934 - accuracy: 0.4806 - val_loss: 0.6941 - val_accuracy: 0.4456\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.6885 - accuracy: 0.5596INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "25/25 [==============================] - 19s 771ms/step - loss: 0.6885 - accuracy: 0.5596 - val_loss: 0.6789 - val_accuracy: 0.6321\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.5774 - accuracy: 0.7370INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "25/25 [==============================] - 21s 827ms/step - loss: 0.5774 - accuracy: 0.7370 - val_loss: 0.5358 - val_accuracy: 0.7668\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.7953INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "25/25 [==============================] - 20s 801ms/step - loss: 0.4875 - accuracy: 0.7953 - val_loss: 0.4155 - val_accuracy: 0.8238\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.8070INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "25/25 [==============================] - 19s 750ms/step - loss: 0.4481 - accuracy: 0.8070 - val_loss: 0.4085 - val_accuracy: 0.8446\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.4688 - accuracy: 0.7953 - val_loss: 0.3996 - val_accuracy: 0.8238\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3950 - accuracy: 0.8277 - val_loss: 0.3657 - val_accuracy: 0.8342\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3825 - accuracy: 0.8394 - val_loss: 0.3580 - val_accuracy: 0.8187\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.8472INFO:tensorflow:Assets written to: classifiers\\temp\\assets\n",
      "25/25 [==============================] - 21s 838ms/step - loss: 0.3944 - accuracy: 0.8472 - val_loss: 0.3472 - val_accuracy: 0.8497\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 0.4379 - accuracy: 0.8174 - val_loss: 0.4169 - val_accuracy: 0.8342\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 1s 37ms/step - loss: 0.3817 - accuracy: 0.8433 - val_loss: 0.3518 - val_accuracy: 0.8497\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3892 - accuracy: 0.8407 - val_loss: 0.3492 - val_accuracy: 0.8446\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3645 - accuracy: 0.8562 - val_loss: 0.4224 - val_accuracy: 0.8135\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3548 - accuracy: 0.8601 - val_loss: 0.3596 - val_accuracy: 0.8446\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3420 - accuracy: 0.8705 - val_loss: 0.3308 - val_accuracy: 0.8342\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3430 - accuracy: 0.8782 - val_loss: 0.3312 - val_accuracy: 0.8290\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3521 - accuracy: 0.8497 - val_loss: 0.3480 - val_accuracy: 0.8446\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3382 - accuracy: 0.8614 - val_loss: 0.4682 - val_accuracy: 0.8031\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3952 - accuracy: 0.8264 - val_loss: 0.3461 - val_accuracy: 0.8394\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3531 - accuracy: 0.8472 - val_loss: 0.3906 - val_accuracy: 0.8342\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3566 - accuracy: 0.8666 - val_loss: 0.3848 - val_accuracy: 0.8342\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3403 - accuracy: 0.8692 - val_loss: 0.3586 - val_accuracy: 0.8394\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.4361 - accuracy: 0.8096 - val_loss: 0.3740 - val_accuracy: 0.8187\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3388 - accuracy: 0.8679 - val_loss: 0.3611 - val_accuracy: 0.8135\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3272 - accuracy: 0.8692 - val_loss: 0.3754 - val_accuracy: 0.8238\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3321 - accuracy: 0.8614 - val_loss: 0.3733 - val_accuracy: 0.8290\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3129 - accuracy: 0.8744 - val_loss: 0.3898 - val_accuracy: 0.8290\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.3209 - accuracy: 0.8731 - val_loss: 0.3544 - val_accuracy: 0.8238\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.3294 - accuracy: 0.8640 - val_loss: 0.3699 - val_accuracy: 0.8187\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3272 - accuracy: 0.8847 - val_loss: 0.4110 - val_accuracy: 0.8238\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3016 - accuracy: 0.8834 - val_loss: 0.3822 - val_accuracy: 0.8135\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3164 - accuracy: 0.8744 - val_loss: 0.3984 - val_accuracy: 0.8135\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2841 - accuracy: 0.8977 - val_loss: 0.3863 - val_accuracy: 0.8135\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2848 - accuracy: 0.8860 - val_loss: 0.3931 - val_accuracy: 0.8290\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2857 - accuracy: 0.8899 - val_loss: 0.4440 - val_accuracy: 0.8187\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3040 - accuracy: 0.8899 - val_loss: 0.4254 - val_accuracy: 0.8135\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2887 - accuracy: 0.8899 - val_loss: 0.4221 - val_accuracy: 0.8187\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3467 - accuracy: 0.8536 - val_loss: 0.6793 - val_accuracy: 0.7047\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.4142 - accuracy: 0.8342 - val_loss: 0.3642 - val_accuracy: 0.8238\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3806 - accuracy: 0.8420 - val_loss: 0.3713 - val_accuracy: 0.8135\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2981 - accuracy: 0.8808 - val_loss: 0.3985 - val_accuracy: 0.8083\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2819 - accuracy: 0.9003 - val_loss: 0.4176 - val_accuracy: 0.8187\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2878 - accuracy: 0.8990 - val_loss: 0.4021 - val_accuracy: 0.8187\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2773 - accuracy: 0.8977 - val_loss: 0.4375 - val_accuracy: 0.8135\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2742 - accuracy: 0.8964 - val_loss: 0.4293 - val_accuracy: 0.8290\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2729 - accuracy: 0.9003 - val_loss: 0.4386 - val_accuracy: 0.8187\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2577 - accuracy: 0.9028 - val_loss: 0.4530 - val_accuracy: 0.8238\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2780 - accuracy: 0.8860 - val_loss: 0.4161 - val_accuracy: 0.8187\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2541 - accuracy: 0.9041 - val_loss: 0.4811 - val_accuracy: 0.8083\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2843 - accuracy: 0.8925 - val_loss: 0.4483 - val_accuracy: 0.8083\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2566 - accuracy: 0.9067 - val_loss: 0.4084 - val_accuracy: 0.8187\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2507 - accuracy: 0.9093 - val_loss: 0.4727 - val_accuracy: 0.8187\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2510 - accuracy: 0.9054 - val_loss: 0.4465 - val_accuracy: 0.8031\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2654 - accuracy: 0.8964 - val_loss: 0.6248 - val_accuracy: 0.7772\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3418 - accuracy: 0.8536 - val_loss: 0.4589 - val_accuracy: 0.8238\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2756 - accuracy: 0.8899 - val_loss: 0.4356 - val_accuracy: 0.8342\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2551 - accuracy: 0.9041 - val_loss: 0.4616 - val_accuracy: 0.8238\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2369 - accuracy: 0.9080 - val_loss: 0.4685 - val_accuracy: 0.8083\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2625 - accuracy: 0.8925 - val_loss: 0.4519 - val_accuracy: 0.8135\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2881 - accuracy: 0.8834 - val_loss: 0.4431 - val_accuracy: 0.8031\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2402 - accuracy: 0.9054 - val_loss: 0.4410 - val_accuracy: 0.8187\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2263 - accuracy: 0.9106 - val_loss: 0.4898 - val_accuracy: 0.7979\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2251 - accuracy: 0.9067 - val_loss: 0.5840 - val_accuracy: 0.8031\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2293 - accuracy: 0.9158 - val_loss: 0.4820 - val_accuracy: 0.8083\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2142 - accuracy: 0.9106 - val_loss: 0.4993 - val_accuracy: 0.8083\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2131 - accuracy: 0.9223 - val_loss: 0.5528 - val_accuracy: 0.7876\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2155 - accuracy: 0.9080 - val_loss: 0.5612 - val_accuracy: 0.8135\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2177 - accuracy: 0.9054 - val_loss: 0.6290 - val_accuracy: 0.8031\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2229 - accuracy: 0.9210 - val_loss: 0.5470 - val_accuracy: 0.7927\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2010 - accuracy: 0.9171 - val_loss: 0.5492 - val_accuracy: 0.8083\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1747 - accuracy: 0.9326 - val_loss: 0.6789 - val_accuracy: 0.7927\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2373 - accuracy: 0.9041 - val_loss: 0.5166 - val_accuracy: 0.7772\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2525 - accuracy: 0.8951 - val_loss: 0.4916 - val_accuracy: 0.7979\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1852 - accuracy: 0.9313 - val_loss: 0.5890 - val_accuracy: 0.7927\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2238 - accuracy: 0.9119 - val_loss: 0.5741 - val_accuracy: 0.7876\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2055 - accuracy: 0.9288 - val_loss: 0.4837 - val_accuracy: 0.8031\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2251 - accuracy: 0.9145 - val_loss: 0.4678 - val_accuracy: 0.8135\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2273 - accuracy: 0.8951 - val_loss: 0.5519 - val_accuracy: 0.8031\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2095 - accuracy: 0.9210 - val_loss: 0.5645 - val_accuracy: 0.7979\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1795 - accuracy: 0.9313 - val_loss: 0.5823 - val_accuracy: 0.7824\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1521 - accuracy: 0.9430 - val_loss: 0.6757 - val_accuracy: 0.7720\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.1919 - accuracy: 0.9275 - val_loss: 0.5271 - val_accuracy: 0.7617\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1795 - accuracy: 0.9339 - val_loss: 0.6192 - val_accuracy: 0.7876\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1557 - accuracy: 0.9456 - val_loss: 0.6861 - val_accuracy: 0.8031\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1913 - accuracy: 0.9262 - val_loss: 0.6231 - val_accuracy: 0.7720\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1481 - accuracy: 0.9443 - val_loss: 0.6286 - val_accuracy: 0.7720\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1430 - accuracy: 0.9443 - val_loss: 0.7334 - val_accuracy: 0.7409\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1505 - accuracy: 0.9456 - val_loss: 0.8055 - val_accuracy: 0.7927\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1495 - accuracy: 0.9430 - val_loss: 0.7315 - val_accuracy: 0.7720\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1532 - accuracy: 0.9417 - val_loss: 0.6728 - val_accuracy: 0.8031\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1691 - accuracy: 0.9404 - val_loss: 0.7000 - val_accuracy: 0.7513\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1486 - accuracy: 0.9378 - val_loss: 0.7846 - val_accuracy: 0.7927\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1458 - accuracy: 0.9404 - val_loss: 0.7434 - val_accuracy: 0.7668\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1259 - accuracy: 0.9430 - val_loss: 0.8371 - val_accuracy: 0.7720\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1620 - accuracy: 0.9391 - val_loss: 0.7416 - val_accuracy: 0.7461\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1822 - accuracy: 0.9339 - val_loss: 0.8134 - val_accuracy: 0.7927\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1711 - accuracy: 0.9210 - val_loss: 0.7562 - val_accuracy: 0.7927\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1066 - accuracy: 0.9663 - val_loss: 0.8553 - val_accuracy: 0.7876\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1021 - accuracy: 0.9624 - val_loss: 0.9429 - val_accuracy: 0.7824\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.0918 - accuracy: 0.9663 - val_loss: 0.9982 - val_accuracy: 0.7617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2417eccc220>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "hypermodel.fit([tv_x[:,:,0], tv_x[:,:,1]], tv_y, epochs=100, validation_data=([test_x[:,:,0], test_x[:,:,1]], test_y), callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "61cc4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "3526e1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2417b76ea90>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(np.argmax(test_y, axis = 1), np.argmax(model.predict([test_x[:,:,0], test_x[:,:,1]]), axis = 1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "4b2bc4b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83        86\n",
      "           1       0.87      0.86      0.86       107\n",
      "\n",
      "    accuracy                           0.85       193\n",
      "   macro avg       0.85      0.85      0.85       193\n",
      "weighted avg       0.85      0.85      0.85       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(np.argmax(test_y, axis = 1), np.argmax(model.predict([test_x[:,:,0], test_x[:,:,1]]), axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cdb1c4",
   "metadata": {},
   "source": [
    "## add to pipe and save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "5537d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def POSclassifier(sentences):\n",
    "    posSentences, detSentences = map(list,zip(*[posTag(sentence) for sentence in sentences]))\n",
    "    res1 = t1.texts_to_sequences(posSentences)\n",
    "    res2 = t2.texts_to_sequences(detSentences)\n",
    "    vocabsize1 = len(t1.word_index)+1\n",
    "    vocabsize2 = len(t2.word_index)+1\n",
    "    \n",
    "    x1 = pad_sequences(\n",
    "    res1, maxlen=200, dtype='int32', padding='post',\n",
    "    truncating='post', value=0\n",
    "    )\n",
    "\n",
    "    x2 = pad_sequences(\n",
    "        res2, maxlen=200, dtype='int32', padding='post',\n",
    "        truncating='post', value=0\n",
    "    )\n",
    "    \n",
    "    results = model.predict([x1, x2])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a9b79a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27068743, 0.72931254]], dtype=float32)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POSclassifier([\"testing methos to predict something\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "257d76db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PosClassifier:\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.nlp = en_core_web_sm.load()\n",
    "        \n",
    "        objectRep = open('classifiers/tok1.obj', \"rb\")\n",
    "        self.t1 = pickle.load(objectRep)\n",
    "        objectRep.close()\n",
    "\n",
    "        objectRep = open('classifiers/tok2.obj', \"rb\")\n",
    "        self.t2 = pickle.load(objectRep)\n",
    "        objectRep.close()\n",
    "        \n",
    "        self.model = tf.keras.models.load_model(\"classifiers/kerasModel\")\n",
    "\n",
    "\n",
    "        \n",
    "    def posTag(self, text):\n",
    "        doc = self.nlp(str(text))\n",
    "        pos = \"\"\n",
    "        dep = \"\"\n",
    "        for token in doc:\n",
    "            pos = pos + token.pos_ + \" \"\n",
    "            dep = dep + token.dep_ + \" \"\n",
    "        return pos, dep\n",
    "    \n",
    "    def predict(self, sentences):\n",
    "        posSentences, detSentences = map(list,zip(*[self.posTag(sentence) for sentence in sentences]))\n",
    "        res1 = self.t1.texts_to_sequences(posSentences)\n",
    "        res2 = self.t2.texts_to_sequences(detSentences)\n",
    "\n",
    "        x1 = pad_sequences(\n",
    "        res1, maxlen=200, dtype='int32', padding='post',\n",
    "        truncating='post', value=0\n",
    "        )\n",
    "\n",
    "        x2 = pad_sequences(\n",
    "            res2, maxlen=200, dtype='int32', padding='post',\n",
    "            truncating='post', value=0\n",
    "        )\n",
    "\n",
    "        results = self.model.predict([x1, x2])\n",
    "        return results\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "72496250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27068743, 0.72931254]], dtype=float32)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Posclassifier = PosClassifier()\n",
    "Posclassifier.predict([\"testing methos to predict something\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "cccce39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "file_pi = open('classifiers/tok1.obj', 'wb') \n",
    "pickle.dump(t1, file_pi)\n",
    "file_pi.close()\n",
    "\n",
    "file_pi = open('classifiers/tok2.obj', 'wb') \n",
    "pickle.dump(t2, file_pi)\n",
    "file_pi.close()\n",
    "\n",
    "file_pi = open('classifiers/tok2.obj', 'wb') \n",
    "pickle.dump(t2, file_pi)\n",
    "file_pi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "3c27aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "file_pi = open('classifiers/POSclassifier4.obj', 'wb') \n",
    "pickle.dump(PosClassifier, file_pi)\n",
    "file_pi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d9e51183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: classifiers/kerasModel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"classifiers/kerasModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba7a4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
